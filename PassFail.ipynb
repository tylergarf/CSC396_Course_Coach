{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a136d87f-81e8-4e65-9d30-75fcd2c6ff7b",
   "metadata": {},
   "source": [
    "# Performing needed imports and boilder plate code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "472cc83c-1425-47ed-b290-9039207e03ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import torch\n",
    "import numpy as np\n",
    "from tqdm.notebook import tqdm\n",
    "import pandas as pd\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "# set this variable to a number to be used as the random seed\n",
    "# or to None if you don't want to set a random seed\n",
    "seed = 1234\n",
    "\n",
    "if seed is not None:\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.manual_seed(seed)\n",
    "        torch.cuda.manual_seed_all(seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c7b032e-e4dc-4cb0-96e2-5b5acaeb463c",
   "metadata": {},
   "source": [
    "# Copied over data cleaning steps from our data cleaning notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5c4c7721-2d24-48e9-bd40-e66aea329f0f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_922274/1122780081.py:6: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  education_data['Gender'] = education_data['Gender'].replace({'Male': 1, 'Female': 0}).astype(int)\n",
      "/tmp/ipykernel_922274/1122780081.py:7: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  education_data['Internet_Access_at_Home'] = education_data['Internet_Access_at_Home'].replace({'Yes': 1, 'No': 0}).astype(int)\n",
      "/tmp/ipykernel_922274/1122780081.py:8: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  education_data['Extracurricular_Activities'] = education_data['Extracurricular_Activities'].replace({'Yes': 1, 'No': 0}).astype(int)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Gender</th>\n",
       "      <th>Age</th>\n",
       "      <th>Department</th>\n",
       "      <th>department index</th>\n",
       "      <th>Attendance (%)</th>\n",
       "      <th>Midterm_Score</th>\n",
       "      <th>Final_Score</th>\n",
       "      <th>Assignments_Avg</th>\n",
       "      <th>Quizzes_Avg</th>\n",
       "      <th>Participation_Score</th>\n",
       "      <th>Projects_Score</th>\n",
       "      <th>Total_Score</th>\n",
       "      <th>Grade</th>\n",
       "      <th>Study_Hours_per_Week</th>\n",
       "      <th>Extracurricular_Activities</th>\n",
       "      <th>Internet_Access_at_Home</th>\n",
       "      <th>Family_Income_Level</th>\n",
       "      <th>Stress_Level (1-10)</th>\n",
       "      <th>Sleep_Hours_per_Night</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>22</td>\n",
       "      <td>Mathematics</td>\n",
       "      <td>0</td>\n",
       "      <td>97.36</td>\n",
       "      <td>40.61</td>\n",
       "      <td>59.61</td>\n",
       "      <td>73.69</td>\n",
       "      <td>53.17</td>\n",
       "      <td>73.4</td>\n",
       "      <td>62.84</td>\n",
       "      <td>59.8865</td>\n",
       "      <td>0</td>\n",
       "      <td>10.3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>5.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>18</td>\n",
       "      <td>Business</td>\n",
       "      <td>1</td>\n",
       "      <td>97.71</td>\n",
       "      <td>57.27</td>\n",
       "      <td>74.00</td>\n",
       "      <td>74.23</td>\n",
       "      <td>98.23</td>\n",
       "      <td>88.0</td>\n",
       "      <td>98.23</td>\n",
       "      <td>81.9170</td>\n",
       "      <td>1</td>\n",
       "      <td>27.1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>4.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>24</td>\n",
       "      <td>Engineering</td>\n",
       "      <td>2</td>\n",
       "      <td>99.52</td>\n",
       "      <td>41.84</td>\n",
       "      <td>63.85</td>\n",
       "      <td>85.85</td>\n",
       "      <td>50.00</td>\n",
       "      <td>4.7</td>\n",
       "      <td>91.22</td>\n",
       "      <td>67.7170</td>\n",
       "      <td>0</td>\n",
       "      <td>12.4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>6.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>24</td>\n",
       "      <td>Engineering</td>\n",
       "      <td>2</td>\n",
       "      <td>90.38</td>\n",
       "      <td>45.65</td>\n",
       "      <td>44.44</td>\n",
       "      <td>68.10</td>\n",
       "      <td>66.27</td>\n",
       "      <td>4.2</td>\n",
       "      <td>55.48</td>\n",
       "      <td>51.6535</td>\n",
       "      <td>0</td>\n",
       "      <td>25.5</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>4.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>23</td>\n",
       "      <td>CS</td>\n",
       "      <td>3</td>\n",
       "      <td>59.41</td>\n",
       "      <td>53.13</td>\n",
       "      <td>61.77</td>\n",
       "      <td>67.66</td>\n",
       "      <td>83.98</td>\n",
       "      <td>64.3</td>\n",
       "      <td>87.43</td>\n",
       "      <td>71.4030</td>\n",
       "      <td>1</td>\n",
       "      <td>13.3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>4.5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Gender  Age   Department  department index  Attendance (%)  Midterm_Score  \\\n",
       "0       0   22  Mathematics                 0           97.36          40.61   \n",
       "1       1   18     Business                 1           97.71          57.27   \n",
       "2       1   24  Engineering                 2           99.52          41.84   \n",
       "3       0   24  Engineering                 2           90.38          45.65   \n",
       "4       0   23           CS                 3           59.41          53.13   \n",
       "\n",
       "   Final_Score  Assignments_Avg  Quizzes_Avg  Participation_Score  \\\n",
       "0        59.61            73.69        53.17                 73.4   \n",
       "1        74.00            74.23        98.23                 88.0   \n",
       "2        63.85            85.85        50.00                  4.7   \n",
       "3        44.44            68.10        66.27                  4.2   \n",
       "4        61.77            67.66        83.98                 64.3   \n",
       "\n",
       "   Projects_Score  Total_Score  Grade  Study_Hours_per_Week  \\\n",
       "0           62.84      59.8865      0                  10.3   \n",
       "1           98.23      81.9170      1                  27.1   \n",
       "2           91.22      67.7170      0                  12.4   \n",
       "3           55.48      51.6535      0                  25.5   \n",
       "4           87.43      71.4030      1                  13.3   \n",
       "\n",
       "   Extracurricular_Activities  Internet_Access_at_Home  Family_Income_Level  \\\n",
       "0                           1                        0                    2   \n",
       "1                           0                        0                    1   \n",
       "2                           1                        0                    1   \n",
       "3                           0                        1                    1   \n",
       "4                           1                        0                    2   \n",
       "\n",
       "   Stress_Level (1-10)  Sleep_Hours_per_Night  \n",
       "0                    1                    5.9  \n",
       "1                    4                    4.3  \n",
       "2                    9                    6.1  \n",
       "3                    8                    4.9  \n",
       "4                    6                    4.5  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "education_data = pd.read_csv('students_clean.csv')\n",
    "\n",
    "\n",
    "education_data.drop('Parent_Education_Level', axis=1, inplace=True) \n",
    "\n",
    "education_data['Gender'] = education_data['Gender'].replace({'Male': 1, 'Female': 0}).astype(int)\n",
    "education_data['Internet_Access_at_Home'] = education_data['Internet_Access_at_Home'].replace({'Yes': 1, 'No': 0}).astype(int)\n",
    "education_data['Extracurricular_Activities'] = education_data['Extracurricular_Activities'].replace({'Yes': 1, 'No': 0}).astype(int)\n",
    "\n",
    "\n",
    "# Low = 1, Medium = 2, High = 3\n",
    "mapper = {'low': 1, 'medium': 2, 'high': 3}\n",
    "\n",
    "education_data['Family_Income_Level'] = (\n",
    "    education_data['Family_Income_Level']\n",
    "      .astype(str)                  # works even if the value is already 1/2/3 or NaN\n",
    "      .str.strip().str.lower()\n",
    "      .map(mapper)                  # returns NaN where no mapping found\n",
    "      .fillna(education_data['Family_Income_Level'])  # keepin the original numeric/blank entries\n",
    "      .astype('Int64')              #  nullable integer dtype\n",
    ")\n",
    "\n",
    "labels = open('departments.txt').read().splitlines()\n",
    "department_mapping = {name: index for index, name in enumerate(labels)}\n",
    "department_indices = education_data['Department'].map(department_mapping)\n",
    "education_data.insert(3, 'department index', department_indices)\n",
    "\n",
    "mapper = {'A': 1, 'B': 1, 'C': 1, 'D':0,'F':0}\n",
    "\n",
    "education_data['Grade'] = (\n",
    "    education_data['Grade']\n",
    "      .astype(str)              # convert everything to string\n",
    "      .str.strip().str.upper()  # remove spaces and standardize to uppercase\n",
    "      .map(mapper)              # map letters to numbers\n",
    ")\n",
    "\n",
    "education_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd384bde-8776-4715-be27-1e4987b0464a",
   "metadata": {},
   "source": [
    "# Now defining our data loader and perceptron"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d7ae6abf-6783-4b0e-a3e9-7b40b2700d14",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset\n",
    "import torch\n",
    "\n",
    "class MyDataset(Dataset):\n",
    "    def __init__(self, df, feature_cols, target_col):\n",
    "        self.df = df\n",
    "        self.feature_cols = feature_cols\n",
    "        self.target_col = target_col\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        row = self.df.iloc[index]\n",
    "        x = torch.tensor(row[self.feature_cols].to_numpy(dtype=np.float32), dtype=torch.float32)\n",
    "        y = torch.tensor(row[self.target_col], dtype=torch.long)  # long for classification\n",
    "        return x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7220d113-16ca-4e46-b771-b8fd567195e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_perceptron(train_dl, n_features, pos_class):\n",
    "    # First initialize the model.\n",
    "    w = np.zeros(n_features)\n",
    "    b = 0\n",
    "    n_errors = 0\n",
    "    weight_steps = []\n",
    "    total_pos_in_train = 0\n",
    "\n",
    "    # Adding this in for debug purposes to track the changes to the weight vectors on each\n",
    "    # round.\n",
    "    \n",
    "    # Average perceptron features\n",
    "    totalW = np.zeros(n_features)\n",
    "    totalB = 0\n",
    "    updates = 0\n",
    "    \n",
    "    \n",
    "    # Now loop through each batch.\n",
    "    for batch_idx, (x, y) in tqdm(enumerate(train_dl), total=len(train_dl),):\n",
    "        \n",
    "        x_curr_np = x.numpy()\n",
    "        y_curr_np = y.numpy()\n",
    "\n",
    "        total_pos_in_train += (y_curr_np == 1).sum(axis=0)\n",
    "        \n",
    "\n",
    "        # Now perform the training/classification loop.\n",
    "        scores = x_curr_np @ w + b\n",
    "       \n",
    "        \n",
    "        y_pred = (scores > 0).astype(int)\n",
    "\n",
    "\n",
    "        # Now we vectorize the update to make this more efficient.\n",
    "        pred_error = y_curr_np - y_pred\n",
    "        n_errors += np.sum(np.abs(pred_error) != 0) # If the pred error is zero then it is correct.\n",
    "\n",
    "        # First append the previous weights to weight steps which will be used for debuging puprposes.\n",
    "        weight_steps.append((pred_error[:,None]*x_curr_np).sum(axis=0).copy())\n",
    "\n",
    "        totalW += w\n",
    "        totalB += b\n",
    "        updates += 1\n",
    "\n",
    "        # For the purposes of the average perceptron we must first store the old w values.\n",
    "        \n",
    "        new_update = (pred_error[:,None]*x_curr_np).sum(axis=0)\n",
    "        w += new_update\n",
    "        b += pred_error.sum()\n",
    "\n",
    "        # Now print out the weights and bias updates every update if we are in debug mode.\n",
    "        \n",
    "\n",
    "    w = totalW/updates\n",
    "    b = totalB/updates\n",
    "    # Now once we are done training the result is the weights and biases.\n",
    "    return (w,b,n_errors,weight_steps.copy(),total_pos_in_train) # I am just copying to avoid weird cases due to mutability of list."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "705c0939-c452-47a5-a973-7007d82813a2",
   "metadata": {},
   "source": [
    "# Create the training and testing partitions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d92df580-200c-4b7d-943e-21adc213eb6d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train rows: 3,600\n",
      "dev rows: 900\n",
      "test rows: 500\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "train_df, test_df = train_test_split(education_data, train_size=0.9,random_state=seed)\n",
    "train_df,dev_df = train_test_split(train_df, train_size=0.8,random_state=seed)\n",
    "\n",
    "train_df.reset_index(inplace=True,drop=True)\n",
    "dev_df.reset_index(inplace=True,drop=True)\n",
    "test_df.reset_index(inplace=True,drop=True)\n",
    "\n",
    "\n",
    "print(f'train rows: {len(train_df.index):,}')\n",
    "print(f'dev rows: {len(dev_df.index):,}')\n",
    "print(f'test rows: {len(test_df.index):,}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "dae62e5f-bc8b-4386-99e1-bbf597d4d830",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "Pass/Fail Distribution in Datasets\n",
      "======================================================================\n",
      "\n",
      "Train Set:\n",
      "  Pass (1): 2105 (58.47%)\n",
      "  Fail (0): 1495 (41.53%)\n",
      "  Total: 3600\n",
      "\n",
      "Dev Set:\n",
      "  Pass (1): 555 (61.67%)\n",
      "  Fail (0): 345 (38.33%)\n",
      "  Total: 900\n",
      "\n",
      "Test Set:\n",
      "  Pass (1): 301 (60.20%)\n",
      "  Fail (0): 199 (39.80%)\n",
      "  Total: 500\n"
     ]
    }
   ],
   "source": [
    "# Check pass/fail distribution in train and dev datasets\n",
    "print(\"=\"*70)\n",
    "print(\"Pass/Fail Distribution in Datasets\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Train set distribution\n",
    "train_pass = (train_df['Grade'] == 1).sum()\n",
    "train_fail = (train_df['Grade'] == 0).sum()\n",
    "train_total = len(train_df)\n",
    "\n",
    "print(f\"\\nTrain Set:\")\n",
    "print(f\"  Pass (1): {train_pass} ({train_pass/train_total*100:.2f}%)\")\n",
    "print(f\"  Fail (0): {train_fail} ({train_fail/train_total*100:.2f}%)\")\n",
    "print(f\"  Total: {train_total}\")\n",
    "\n",
    "# Dev set distribution\n",
    "dev_pass = (dev_df['Grade'] == 1).sum()\n",
    "dev_fail = (dev_df['Grade'] == 0).sum()\n",
    "dev_total = len(dev_df)\n",
    "\n",
    "print(f\"\\nDev Set:\")\n",
    "print(f\"  Pass (1): {dev_pass} ({dev_pass/dev_total*100:.2f}%)\")\n",
    "print(f\"  Fail (0): {dev_fail} ({dev_fail/dev_total*100:.2f}%)\")\n",
    "print(f\"  Total: {dev_total}\")\n",
    "\n",
    "# Test set distribution\n",
    "test_pass = (test_df['Grade'] == 1).sum()\n",
    "test_fail = (test_df['Grade'] == 0).sum()\n",
    "test_total = len(test_df)\n",
    "\n",
    "print(f\"\\nTest Set:\")\n",
    "print(f\"  Pass (1): {test_pass} ({test_pass/test_total*100:.2f}%)\")\n",
    "print(f\"  Fail (0): {test_fail} ({test_fail/test_total*100:.2f}%)\")\n",
    "print(f\"  Total: {test_total}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a9940c6-6dc7-4917-be9d-ac08f8c50b4c",
   "metadata": {},
   "source": [
    "# Before Midterm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8148d38e-4f37-4f1e-8028-7ad1e564ae1e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7772051628cd420ab3d8f1f6515b0083",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/57 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------Averaged Perceptron (10 perceptrons)------------------------------\n",
      "\n",
      "Averaged weight vector shape: [-902.41421228 1211.96075794  589.88649402 1127.07189787   16.47368421\n",
      " -125.12280702  -95.69824462  -13.36842105]\n",
      "Averaged bias value: -20.9649\n",
      "\n",
      "The number of correct preds was 555 for acc of 61.66666666666667%\n",
      "The number of pos preds was 900 and neg num was 0\n",
      "\n",
      "======================================================================\n",
      "Detailed Evaluation Metrics:\n",
      "======================================================================\n",
      "Accuracy: 61.67%\n",
      "Precision: 0.6167\n",
      "Recall: 1.0000\n",
      "F1-Score: 0.7629\n",
      "\n",
      "Confusion Matrix:\n",
      "                Predicted\n",
      "              Fail    Pass\n",
      "Actual Fail      0    345\n",
      "       Pass      0    555\n",
      "\n",
      "Predictions breakdown:\n",
      "  Predicted Fail (0): 0\n",
      "  Predicted Pass (1): 900\n",
      "  Actual Fail (0): 345\n",
      "  Actual Pass (1): 555\n"
     ]
    }
   ],
   "source": [
    "# Averaged Perceptron: Train 10 perceptrons and average their weights\n",
    "n_perceptrons = 10\n",
    "weight_vecs = []\n",
    "bias_vecs = []\n",
    "features_lst = ['Attendance (%)', \\\n",
    "       'Assignments_Avg', 'Quizzes_Avg', \\\n",
    "       'Participation_Score', 'Internet_Access_at_Home', \\\n",
    "       'Stress_Level (1-10)', \\\n",
    "       'Sleep_Hours_per_Night', 'Extracurricular_Activities']\n",
    "num_feat = len(features_lst)\n",
    "batch_size=64\n",
    "shuffle = True\n",
    "\n",
    "\n",
    "train_ds = MyDataset(train_df, features_lst, 'Grade')\n",
    "train_dl = DataLoader(train_ds, batch_size=batch_size, shuffle=shuffle)\n",
    "w_avg, b_avg, error_avg, weight_hist_avg, tot_train_pos_avg = train_perceptron(train_dl, num_feat, pos_class=1)\n",
    "\n",
    "\n",
    "print(f\"-------------------Averaged Perceptron (10 perceptrons)------------------------------\\n\")\n",
    "print(f\"Averaged weight vector shape: {w_avg}\")\n",
    "print(f\"Averaged bias value: {b_avg:.4f}\\n\")\n",
    "\n",
    "# Test on dev.\n",
    "X_dev_a = dev_df[features_lst].to_numpy()\n",
    "dev_y_true = dev_df['Grade'].to_numpy()\n",
    "dev_y_pred = ((X_dev_a @ w_avg + b_avg) > 0).astype(int)\n",
    "n_correct_dev = (dev_y_true==dev_y_pred).sum(axis=0)\n",
    "\n",
    "print(f\"The number of correct preds was {n_correct_dev} for acc of {(n_correct_dev/dev_y_true.shape[0])*100}%\")\n",
    "print(f\"The number of pos preds was {(dev_y_pred==1).sum(axis=0)} and neg num was {(dev_y_pred==0).sum(axis=0)}\")\n",
    "\n",
    "# Additional detailed metrics\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix\n",
    "\n",
    "accuracy = accuracy_score(dev_y_true, dev_y_pred)\n",
    "precision = precision_score(dev_y_true, dev_y_pred, zero_division=0)\n",
    "recall = recall_score(dev_y_true, dev_y_pred, zero_division=0)\n",
    "f1 = f1_score(dev_y_true, dev_y_pred, zero_division=0)\n",
    "cm = confusion_matrix(dev_y_true, dev_y_pred)\n",
    "\n",
    "print(f\"\\n{'='*70}\")\n",
    "print(\"Detailed Evaluation Metrics:\")\n",
    "print(f\"{'='*70}\")\n",
    "print(f\"Accuracy: {accuracy*100:.2f}%\")\n",
    "print(f\"Precision: {precision:.4f}\")\n",
    "print(f\"Recall: {recall:.4f}\")\n",
    "print(f\"F1-Score: {f1:.4f}\")\n",
    "\n",
    "print(f\"\\nConfusion Matrix:\")\n",
    "print(f\"                Predicted\")\n",
    "print(f\"              Fail    Pass\")\n",
    "print(f\"Actual Fail   {cm[0,0]:4d}   {cm[0,1]:4d}\")\n",
    "print(f\"       Pass   {cm[1,0]:4d}   {cm[1,1]:4d}\")\n",
    "\n",
    "print(f\"\\nPredictions breakdown:\")\n",
    "print(f\"  Predicted Fail (0): {(dev_y_pred==0).sum()}\")\n",
    "print(f\"  Predicted Pass (1): {(dev_y_pred==1).sum()}\")\n",
    "print(f\"  Actual Fail (0): {(dev_y_true==0).sum()}\")\n",
    "print(f\"  Actual Pass (1): {(dev_y_true==1).sum()}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e53ee25d-dc0c-4190-9dcd-2dc9fa9225dc",
   "metadata": {},
   "source": [
    "# After Midterm and before Final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "171a5f7a-2ee5-4a90-9165-0dba15049870",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ea0daa1cefef43f1829b9594168fdf51",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/57 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------Averaged Perceptron (10 perceptrons)------------------------------\n",
      "\n",
      "Averaged weight vector shape: [-1512.25398522   -16.03508772  2021.91441626  1290.83883373\n",
      "   -32.78604507  1808.45085943  -149.54385965  -152.21753998]\n",
      "Averaged bias value: -25.7895\n",
      "\n",
      "The number of correct preds was 555 for acc of 61.66666666666667%\n",
      "The number of pos preds was 900 and neg num was 0\n",
      "\n",
      "======================================================================\n",
      "Detailed Evaluation Metrics:\n",
      "======================================================================\n",
      "Accuracy: 61.67%\n",
      "Precision: 0.6167\n",
      "Recall: 1.0000\n",
      "F1-Score: 0.7629\n",
      "\n",
      "Confusion Matrix:\n",
      "                Predicted\n",
      "              Fail    Pass\n",
      "Actual Fail      0    345\n",
      "       Pass      0    555\n",
      "\n",
      "Predictions breakdown:\n",
      "  Predicted Fail (0): 0\n",
      "  Predicted Pass (1): 900\n",
      "  Actual Fail (0): 345\n",
      "  Actual Pass (1): 555\n"
     ]
    }
   ],
   "source": [
    "# Averaged Perceptron: Train 10 perceptrons and average their weights\n",
    "n_perceptrons = 10\n",
    "weight_vecs = []\n",
    "bias_vecs = []\n",
    "features_lst = ['Attendance (%)', 'Extracurricular_Activities', 'Midterm_Score', \\\n",
    "       'Assignments_Avg', 'Quizzes_Avg', \\\n",
    "       'Participation_Score', \\\n",
    "       'Stress_Level (1-10)', \\\n",
    "       'Sleep_Hours_per_Night']\n",
    "num_feat = len(features_lst)\n",
    "batch_size=64\n",
    "shuffle = True\n",
    "\n",
    "train_ds = MyDataset(train_df, features_lst, 'Grade')\n",
    "train_dl = DataLoader(train_ds, batch_size=batch_size, shuffle=shuffle)\n",
    "w_avg, b_avg, error_avg, weight_hist_avg, tot_train_pos_avg = train_perceptron(train_dl, num_feat, pos_class=1)\n",
    "\n",
    "print(f\"-------------------Averaged Perceptron (10 perceptrons)------------------------------\\n\")\n",
    "print(f\"Averaged weight vector shape: {w_avg}\")\n",
    "print(f\"Averaged bias value: {b_avg:.4f}\\n\")\n",
    "\n",
    "# Test on dev.\n",
    "X_dev_a = dev_df[features_lst].to_numpy()\n",
    "dev_y_true = dev_df['Grade'].to_numpy()\n",
    "dev_y_pred = ((X_dev_a @ w_avg + b_avg) > 0).astype(int)\n",
    "n_correct_dev = (dev_y_true==dev_y_pred).sum(axis=0)\n",
    "\n",
    "print(f\"The number of correct preds was {n_correct_dev} for acc of {(n_correct_dev/dev_y_true.shape[0])*100}%\")\n",
    "print(f\"The number of pos preds was {(dev_y_pred==1).sum(axis=0)} and neg num was {(dev_y_pred==0).sum(axis=0)}\")\n",
    "\n",
    "# Additional detailed metrics\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix\n",
    "\n",
    "accuracy = accuracy_score(dev_y_true, dev_y_pred)\n",
    "precision = precision_score(dev_y_true, dev_y_pred, zero_division=0)\n",
    "recall = recall_score(dev_y_true, dev_y_pred, zero_division=0)\n",
    "f1 = f1_score(dev_y_true, dev_y_pred, zero_division=0)\n",
    "cm = confusion_matrix(dev_y_true, dev_y_pred)\n",
    "\n",
    "print(f\"\\n{'='*70}\")\n",
    "print(\"Detailed Evaluation Metrics:\")\n",
    "print(f\"{'='*70}\")\n",
    "print(f\"Accuracy: {accuracy*100:.2f}%\")\n",
    "print(f\"Precision: {precision:.4f}\")\n",
    "print(f\"Recall: {recall:.4f}\")\n",
    "print(f\"F1-Score: {f1:.4f}\")\n",
    "\n",
    "print(f\"\\nConfusion Matrix:\")\n",
    "print(f\"                Predicted\")\n",
    "print(f\"              Fail    Pass\")\n",
    "print(f\"Actual Fail   {cm[0,0]:4d}   {cm[0,1]:4d}\")\n",
    "print(f\"       Pass   {cm[1,0]:4d}   {cm[1,1]:4d}\")\n",
    "\n",
    "print(f\"\\nPredictions breakdown:\")\n",
    "print(f\"  Predicted Fail (0): {(dev_y_pred==0).sum()}\")\n",
    "print(f\"  Predicted Pass (1): {(dev_y_pred==1).sum()}\")\n",
    "print(f\"  Actual Fail (0): {(dev_y_true==0).sum()}\")\n",
    "print(f\"  Actual Pass (1): {(dev_y_true==1).sum()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80d8a928-6a3c-4c0c-bc9a-523a88141e52",
   "metadata": {},
   "source": [
    "# After Final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "12eafc0b-00f4-422e-9f14-1a60c78849d6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "93b5df830553454bab7c8d59407e683a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/57 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------Averaged Perceptron (10 perceptrons)------------------------------\n",
      "\n",
      "Averaged weight vector shape: [-3080.00084519   -31.8245614    731.06318872  3859.74365007\n",
      "  -280.11223863  -931.06346619   763.19641703  3028.58531316\n",
      "  -178.77192982  -275.18245616]\n",
      "Averaged bias value: -44.5965\n",
      "\n",
      "The number of correct preds was 556 for acc of 61.77777777777778%\n",
      "The number of pos preds was 899 and neg num was 1\n",
      "\n",
      "======================================================================\n",
      "Detailed Evaluation Metrics:\n",
      "======================================================================\n",
      "Accuracy: 61.78%\n",
      "Precision: 0.6174\n",
      "Recall: 1.0000\n",
      "F1-Score: 0.7634\n",
      "\n",
      "Confusion Matrix:\n",
      "                Predicted\n",
      "              Fail    Pass\n",
      "Actual Fail      1    344\n",
      "       Pass      0    555\n",
      "\n",
      "Predictions breakdown:\n",
      "  Predicted Fail (0): 1\n",
      "  Predicted Pass (1): 899\n",
      "  Actual Fail (0): 345\n",
      "  Actual Pass (1): 555\n"
     ]
    }
   ],
   "source": [
    "# Averaged Perceptron: Train 10 perceptrons and average their weights\n",
    "n_perceptrons = 10\n",
    "weight_vecs = []\n",
    "bias_vecs = []\n",
    "features_lst = ['Attendance (%)', 'Extracurricular_Activities', 'Midterm_Score', \\\n",
    "       'Final_Score', 'Assignments_Avg', 'Quizzes_Avg', \\\n",
    "       'Participation_Score', 'Projects_Score', \\\n",
    "       'Stress_Level (1-10)', \\\n",
    "       'Sleep_Hours_per_Night']\n",
    "num_feat = len(features_lst)\n",
    "batch_size=64\n",
    "shuffle = True\n",
    "\n",
    "train_ds = MyDataset(train_df, features_lst, 'Grade')\n",
    "train_dl = DataLoader(train_ds, batch_size=batch_size, shuffle=shuffle)\n",
    "w_avg, b_avg, error_avg, weight_hist_avg, tot_train_pos_avg = train_perceptron(train_dl, num_feat, pos_class=1)\n",
    "\n",
    "\n",
    "print(f\"-------------------Averaged Perceptron (10 perceptrons)------------------------------\\n\")\n",
    "print(f\"Averaged weight vector shape: {w_avg}\")\n",
    "print(f\"Averaged bias value: {b_avg:.4f}\\n\")\n",
    "\n",
    "# Test on dev.\n",
    "X_dev_a = dev_df[features_lst].to_numpy()\n",
    "dev_y_true = dev_df['Grade'].to_numpy()\n",
    "dev_y_pred = ((X_dev_a @ w_avg + b_avg) > 0).astype(int)\n",
    "n_correct_dev = (dev_y_true==dev_y_pred).sum(axis=0)\n",
    "\n",
    "print(f\"The number of correct preds was {n_correct_dev} for acc of {(n_correct_dev/dev_y_true.shape[0])*100}%\")\n",
    "print(f\"The number of pos preds was {(dev_y_pred==1).sum(axis=0)} and neg num was {(dev_y_pred==0).sum(axis=0)}\")\n",
    "\n",
    "# Additional detailed metrics\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix\n",
    "\n",
    "accuracy = accuracy_score(dev_y_true, dev_y_pred)\n",
    "precision = precision_score(dev_y_true, dev_y_pred, zero_division=0)\n",
    "recall = recall_score(dev_y_true, dev_y_pred, zero_division=0)\n",
    "f1 = f1_score(dev_y_true, dev_y_pred, zero_division=0)\n",
    "cm = confusion_matrix(dev_y_true, dev_y_pred)\n",
    "\n",
    "print(f\"\\n{'='*70}\")\n",
    "print(\"Detailed Evaluation Metrics:\")\n",
    "print(f\"{'='*70}\")\n",
    "print(f\"Accuracy: {accuracy*100:.2f}%\")\n",
    "print(f\"Precision: {precision:.4f}\")\n",
    "print(f\"Recall: {recall:.4f}\")\n",
    "print(f\"F1-Score: {f1:.4f}\")\n",
    "\n",
    "print(f\"\\nConfusion Matrix:\")\n",
    "print(f\"                Predicted\")\n",
    "print(f\"              Fail    Pass\")\n",
    "print(f\"Actual Fail   {cm[0,0]:4d}   {cm[0,1]:4d}\")\n",
    "print(f\"       Pass   {cm[1,0]:4d}   {cm[1,1]:4d}\")\n",
    "\n",
    "print(f\"\\nPredictions breakdown:\")\n",
    "print(f\"  Predicted Fail (0): {(dev_y_pred==0).sum()}\")\n",
    "print(f\"  Predicted Pass (1): {(dev_y_pred==1).sum()}\")\n",
    "print(f\"  Actual Fail (0): {(dev_y_true==0).sum()}\")\n",
    "print(f\"  Actual Pass (1): {(dev_y_true==1).sum()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "71f40813-920e-4707-bfed-f2398d86c486",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- 15 examples: Pred Pass but Actual Fail ---\n",
      "    Attendance (%)  Extracurricular_Activities  Midterm_Score  Final_Score  \\\n",
      "1            92.68                           1          60.33        70.99   \n",
      "8            70.32                           1          41.14        83.66   \n",
      "13           77.36                           0          97.94        41.39   \n",
      "16           68.04                           1          57.49        42.38   \n",
      "19           52.96                           0          78.38        55.22   \n",
      "20           68.14                           1          95.82        56.38   \n",
      "22           72.90                           1          97.19        46.40   \n",
      "23           87.30                           0          75.40        49.35   \n",
      "27           96.62                           0          79.96        50.66   \n",
      "31           66.87                           0          72.25        88.65   \n",
      "32           68.47                           1          57.07        60.64   \n",
      "35           88.60                           1          51.46        43.25   \n",
      "36           57.46                           0          47.28        51.52   \n",
      "37           65.60                           0          76.57        75.55   \n",
      "40           56.27                           1          68.07        42.62   \n",
      "\n",
      "    Assignments_Avg  Quizzes_Avg  Participation_Score  Projects_Score  \\\n",
      "1             85.67        55.46                  5.7           76.40   \n",
      "8             66.76        61.46                 68.2           62.64   \n",
      "13            95.68        94.95                 23.7           60.73   \n",
      "16            77.73        81.72                 55.6           69.32   \n",
      "19            60.21        76.98                 82.2           69.37   \n",
      "20            69.11        74.48                 64.0           56.80   \n",
      "22            64.63        84.68                  4.5           59.90   \n",
      "23            91.45        70.60                 50.5           52.87   \n",
      "27            77.49        54.35                 36.4           71.42   \n",
      "31            54.94        77.86                 13.3           66.85   \n",
      "32            53.66        85.30                 26.5           74.31   \n",
      "35            73.85        79.19                 49.8           57.23   \n",
      "36            57.06        88.44                 72.3           51.13   \n",
      "37            54.99        54.26                 21.3           53.73   \n",
      "40            67.12        61.10                 86.7           62.50   \n",
      "\n",
      "    Stress_Level (1-10)  Sleep_Hours_per_Night  Grade  \n",
      "1                     3                    8.2      0  \n",
      "8                     8                    4.4      0  \n",
      "13                    1                    7.6      0  \n",
      "16                    4                    7.3      0  \n",
      "19                    1                    8.0      0  \n",
      "20                    7                    6.9      0  \n",
      "22                    3                    7.1      0  \n",
      "23                   10                    4.8      0  \n",
      "27                    5                    8.3      0  \n",
      "31                    6                    6.2      0  \n",
      "32                   10                    8.7      0  \n",
      "35                   10                    8.2      0  \n",
      "36                    1                    6.4      0  \n",
      "37                    8                    7.3      0  \n",
      "40                    4                    7.5      0  \n",
      "\n",
      "--- 10 examples: Pred Fail but Actual Pass ---\n",
      "Empty DataFrame\n",
      "Columns: [Attendance (%), Extracurricular_Activities, Midterm_Score, Final_Score, Assignments_Avg, Quizzes_Avg, Participation_Score, Projects_Score, Stress_Level (1-10), Sleep_Hours_per_Night, Grade]\n",
      "Index: []\n"
     ]
    }
   ],
   "source": [
    "# Get indices where prediction = 1 but true = 0  (False Positives)\n",
    "idx_pred_pass_actual_fail = np.where((dev_y_pred == 1) & (dev_y_true == 0))[0]\n",
    "\n",
    "# Get indices where prediction = 0 but true = 1  (False Negatives)\n",
    "idx_pred_fail_actual_pass = np.where((dev_y_pred == 0) & (dev_y_true == 1))[0]\n",
    "\n",
    "# Extract the requested number of examples using iloc\n",
    "features_to_show = features_lst + ['Grade']\n",
    "fp_examples = dev_df.iloc[idx_pred_pass_actual_fail][features_to_show].head(15)\n",
    "fn_examples = dev_df.iloc[idx_pred_fail_actual_pass][features_to_show].head(10)\n",
    "\n",
    "\n",
    "\n",
    "print(\"\\n--- 15 examples: Pred Pass but Actual Fail ---\")\n",
    "print(fp_examples)\n",
    "\n",
    "print(\"\\n--- 10 examples: Pred Fail but Actual Pass ---\")\n",
    "print(fn_examples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0b86c898-eb2a-4e36-8396-beeb3c016fe8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Averaged Perceptron Weights by Feature ===\n",
      "\n",
      "Attendance (%)              : -3080.000845\n",
      "Extracurricular_Activities  : -31.824561\n",
      "Midterm_Score               : 731.063189\n",
      "Final_Score                 : 3859.743650\n",
      "Assignments_Avg             : -280.112239\n",
      "Quizzes_Avg                 : -931.063466\n",
      "Participation_Score         : 763.196417\n",
      "Projects_Score              : 3028.585313\n",
      "Stress_Level (1-10)         : -178.771930\n",
      "Sleep_Hours_per_Night       : -275.182456\n",
      "\n",
      "Bias (b_avg): -44.596491\n"
     ]
    }
   ],
   "source": [
    "print(\"=== Averaged Perceptron Weights by Feature ===\\n\")\n",
    "\n",
    "for feature, weight in zip(features_lst, w_avg):\n",
    "    print(f\"{feature:27s} : {weight:.6f}\")\n",
    "\n",
    "print(f\"\\nBias (b_avg): {b_avg:.6f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4c58463b-8715-4230-bd92-5e171c4be807",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of correct preds was 302 for acc of 60.4%\n",
      "The number of pos preds was 499 and neg num was 1\n",
      "\n",
      "======================================================================\n",
      "Detailed Evaluation Metrics:\n",
      "======================================================================\n",
      "Accuracy: 60.40%\n",
      "Precision: 0.6032\n",
      "Recall: 1.0000\n",
      "F1-Score: 0.7525\n",
      "\n",
      "Confusion Matrix:\n",
      "                Predicted\n",
      "              Fail    Pass\n",
      "Actual Fail      1    198\n",
      "       Pass      0    301\n",
      "\n",
      "Predictions breakdown:\n",
      "  Predicted Fail (0): 1\n",
      "  Predicted Pass (1): 499\n",
      "  Actual Fail (0): 199\n",
      "  Actual Pass (1): 301\n"
     ]
    }
   ],
   "source": [
    "# Test on Test.\n",
    "X_test_a = test_df[features_lst].to_numpy()\n",
    "test_y_true = test_df['Grade'].to_numpy()\n",
    "test_y_pred = ((X_test_a @ w_avg + b_avg) > 0).astype(int)\n",
    "n_correct_test = (test_y_true==test_y_pred).sum(axis=0)\n",
    "\n",
    "print(f\"The number of correct preds was {n_correct_test} for acc of {(n_correct_test/test_y_true.shape[0])*100}%\")\n",
    "print(f\"The number of pos preds was {(test_y_pred==1).sum(axis=0)} and neg num was {(test_y_pred==0).sum(axis=0)}\")\n",
    "\n",
    "# Additional detailed metrics\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix\n",
    "\n",
    "accuracy = accuracy_score(test_y_true, test_y_pred)\n",
    "precision = precision_score(test_y_true, test_y_pred, zero_division=0)\n",
    "recall = recall_score(test_y_true, test_y_pred, zero_division=0)\n",
    "f1 = f1_score(test_y_true, test_y_pred, zero_division=0)\n",
    "cm = confusion_matrix(test_y_true, test_y_pred)\n",
    "\n",
    "print(f\"\\n{'='*70}\")\n",
    "print(\"Detailed Evaluation Metrics:\")\n",
    "print(f\"{'='*70}\")\n",
    "print(f\"Accuracy: {accuracy*100:.2f}%\")\n",
    "print(f\"Precision: {precision:.4f}\")\n",
    "print(f\"Recall: {recall:.4f}\")\n",
    "print(f\"F1-Score: {f1:.4f}\")\n",
    "\n",
    "print(f\"\\nConfusion Matrix:\")\n",
    "print(f\"                Predicted\")\n",
    "print(f\"              Fail    Pass\")\n",
    "print(f\"Actual Fail   {cm[0,0]:4d}   {cm[0,1]:4d}\")\n",
    "print(f\"       Pass   {cm[1,0]:4d}   {cm[1,1]:4d}\")\n",
    "\n",
    "print(f\"\\nPredictions breakdown:\")\n",
    "print(f\"  Predicted Fail (0): {(test_y_pred==0).sum()}\")\n",
    "print(f\"  Predicted Pass (1): {(test_y_pred==1).sum()}\")\n",
    "print(f\"  Actual Fail (0): {(test_y_true==0).sum()}\")\n",
    "print(f\"  Actual Pass (1): {(test_y_true==1).sum()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "633123ca-0df0-4d1a-a2f8-23b57b2adbf5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc2cdb36-a927-472d-a1d9-493d8e7635ee",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81de7c17-6458-4e7d-9767-4309dbade652",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
