{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a136d87f-81e8-4e65-9d30-75fcd2c6ff7b",
   "metadata": {},
   "source": [
    "# Performing needed imports and boilder plate code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "472cc83c-1425-47ed-b290-9039207e03ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "from tqdm.notebook import tqdm\n",
    "import pandas as pd\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "# set this variable to a number to be used as the random seed\n",
    "# or to None if you don't want to set a random seed\n",
    "seed = 1234\n",
    "\n",
    "if seed is not None:\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.manual_seed(seed)\n",
    "        torch.cuda.manual_seed_all(seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c7b032e-e4dc-4cb0-96e2-5b5acaeb463c",
   "metadata": {},
   "source": [
    "# Copied over data cleaning steps from our data cleaning notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5c4c7721-2d24-48e9-bd40-e66aea329f0f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_709327/2188593247.py:6: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  education_data['Gender'] = education_data['Gender'].replace({'Male': 1, 'Female': 0}).astype(int)\n",
      "/tmp/ipykernel_709327/2188593247.py:7: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  education_data['Internet_Access_at_Home'] = education_data['Internet_Access_at_Home'].replace({'Yes': 1, 'No': 0}).astype(int)\n",
      "/tmp/ipykernel_709327/2188593247.py:8: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  education_data['Extracurricular_Activities'] = education_data['Extracurricular_Activities'].replace({'Yes': 1, 'No': 0}).astype(int)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Gender</th>\n",
       "      <th>Age</th>\n",
       "      <th>department index</th>\n",
       "      <th>Attendance (%)</th>\n",
       "      <th>Midterm_Score</th>\n",
       "      <th>Final_Score</th>\n",
       "      <th>Assignments_Avg</th>\n",
       "      <th>Quizzes_Avg</th>\n",
       "      <th>Participation_Score</th>\n",
       "      <th>Projects_Score</th>\n",
       "      <th>Total_Score</th>\n",
       "      <th>Grade</th>\n",
       "      <th>Study_Hours_per_Week</th>\n",
       "      <th>Extracurricular_Activities</th>\n",
       "      <th>Internet_Access_at_Home</th>\n",
       "      <th>Family_Income_Level</th>\n",
       "      <th>Stress_Level (1-10)</th>\n",
       "      <th>Sleep_Hours_per_Night</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>22</td>\n",
       "      <td>0</td>\n",
       "      <td>97.36</td>\n",
       "      <td>40.61</td>\n",
       "      <td>59.61</td>\n",
       "      <td>73.69</td>\n",
       "      <td>53.17</td>\n",
       "      <td>73.4</td>\n",
       "      <td>62.84</td>\n",
       "      <td>59.8865</td>\n",
       "      <td>0</td>\n",
       "      <td>10.3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>5.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>18</td>\n",
       "      <td>1</td>\n",
       "      <td>97.71</td>\n",
       "      <td>57.27</td>\n",
       "      <td>74.00</td>\n",
       "      <td>74.23</td>\n",
       "      <td>98.23</td>\n",
       "      <td>88.0</td>\n",
       "      <td>98.23</td>\n",
       "      <td>81.9170</td>\n",
       "      <td>1</td>\n",
       "      <td>27.1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>4.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>24</td>\n",
       "      <td>2</td>\n",
       "      <td>99.52</td>\n",
       "      <td>41.84</td>\n",
       "      <td>63.85</td>\n",
       "      <td>85.85</td>\n",
       "      <td>50.00</td>\n",
       "      <td>4.7</td>\n",
       "      <td>91.22</td>\n",
       "      <td>67.7170</td>\n",
       "      <td>0</td>\n",
       "      <td>12.4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>6.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>24</td>\n",
       "      <td>2</td>\n",
       "      <td>90.38</td>\n",
       "      <td>45.65</td>\n",
       "      <td>44.44</td>\n",
       "      <td>68.10</td>\n",
       "      <td>66.27</td>\n",
       "      <td>4.2</td>\n",
       "      <td>55.48</td>\n",
       "      <td>51.6535</td>\n",
       "      <td>0</td>\n",
       "      <td>25.5</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>4.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>23</td>\n",
       "      <td>3</td>\n",
       "      <td>59.41</td>\n",
       "      <td>53.13</td>\n",
       "      <td>61.77</td>\n",
       "      <td>67.66</td>\n",
       "      <td>83.98</td>\n",
       "      <td>64.3</td>\n",
       "      <td>87.43</td>\n",
       "      <td>71.4030</td>\n",
       "      <td>1</td>\n",
       "      <td>13.3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>4.5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Gender  Age  department index  Attendance (%)  Midterm_Score  Final_Score  \\\n",
       "0       0   22                 0           97.36          40.61        59.61   \n",
       "1       1   18                 1           97.71          57.27        74.00   \n",
       "2       1   24                 2           99.52          41.84        63.85   \n",
       "3       0   24                 2           90.38          45.65        44.44   \n",
       "4       0   23                 3           59.41          53.13        61.77   \n",
       "\n",
       "   Assignments_Avg  Quizzes_Avg  Participation_Score  Projects_Score  \\\n",
       "0            73.69        53.17                 73.4           62.84   \n",
       "1            74.23        98.23                 88.0           98.23   \n",
       "2            85.85        50.00                  4.7           91.22   \n",
       "3            68.10        66.27                  4.2           55.48   \n",
       "4            67.66        83.98                 64.3           87.43   \n",
       "\n",
       "   Total_Score  Grade  Study_Hours_per_Week  Extracurricular_Activities  \\\n",
       "0      59.8865      0                  10.3                           1   \n",
       "1      81.9170      1                  27.1                           0   \n",
       "2      67.7170      0                  12.4                           1   \n",
       "3      51.6535      0                  25.5                           0   \n",
       "4      71.4030      1                  13.3                           1   \n",
       "\n",
       "   Internet_Access_at_Home  Family_Income_Level  Stress_Level (1-10)  \\\n",
       "0                        0                    2                    1   \n",
       "1                        0                    1                    4   \n",
       "2                        0                    1                    9   \n",
       "3                        1                    1                    8   \n",
       "4                        0                    2                    6   \n",
       "\n",
       "   Sleep_Hours_per_Night  \n",
       "0                    5.9  \n",
       "1                    4.3  \n",
       "2                    6.1  \n",
       "3                    4.9  \n",
       "4                    4.5  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "education_data = pd.read_csv('students_clean.csv')\n",
    "\n",
    "\n",
    "education_data.drop('Parent_Education_Level', axis=1, inplace=True) \n",
    "\n",
    "education_data['Gender'] = education_data['Gender'].replace({'Male': 1, 'Female': 0}).astype(int)\n",
    "education_data['Internet_Access_at_Home'] = education_data['Internet_Access_at_Home'].replace({'Yes': 1, 'No': 0}).astype(int)\n",
    "education_data['Extracurricular_Activities'] = education_data['Extracurricular_Activities'].replace({'Yes': 1, 'No': 0}).astype(int)\n",
    "\n",
    "\n",
    "# Low = 1, Medium = 2, High = 3\n",
    "mapper = {'low': 1, 'medium': 2, 'high': 3}\n",
    "\n",
    "education_data['Family_Income_Level'] = (\n",
    "    education_data['Family_Income_Level']\n",
    "      .astype(str)                  # works even if the value is already 1/2/3 or NaN\n",
    "      .str.strip().str.lower()\n",
    "      .map(mapper)                  # returns NaN where no mapping found\n",
    "      .fillna(education_data['Family_Income_Level'])  # keepin the original numeric/blank entries\n",
    "      .astype('Int64')              #  nullable integer dtype\n",
    ")\n",
    "\n",
    "labels = open('departments.txt').read().splitlines()\n",
    "department_mapping = {name: index for index, name in enumerate(labels)}\n",
    "department_indices = education_data['Department'].map(department_mapping)\n",
    "education_data.insert(3, 'department index', department_indices)\n",
    "\n",
    "mapper = {'A': 1, 'B': 1, 'C': 1, 'D':0,'F':0}\n",
    "\n",
    "education_data['Grade'] = (\n",
    "    education_data['Grade']\n",
    "      .astype(str)              # convert everything to string\n",
    "      .str.strip().str.upper()  # remove spaces and standardize to uppercase\n",
    "      .map(mapper)              # map letters to numbers\n",
    ")\n",
    "education_data = education_data.drop(columns='Department')\n",
    "education_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd384bde-8776-4715-be27-1e4987b0464a",
   "metadata": {},
   "source": [
    "# Now defining our data loader and perceptron"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d7ae6abf-6783-4b0e-a3e9-7b40b2700d14",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset\n",
    "import torch\n",
    "\n",
    "class MyDataset(Dataset):\n",
    "    def __init__(self, df, feature_cols, target_col):\n",
    "        self.df = df\n",
    "        self.feature_cols = feature_cols\n",
    "        self.target_col = target_col\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        row = self.df.iloc[index]\n",
    "        x = torch.tensor(row[self.feature_cols].to_numpy(dtype=np.float32), dtype=torch.float32)\n",
    "        y = torch.tensor(row[self.target_col], dtype=torch.long)  # long for classification\n",
    "        return x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7220d113-16ca-4e46-b771-b8fd567195e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_perceptron(train_dl, n_features, pos_class):\n",
    "    # First initialize the model.\n",
    "    w = np.zeros(n_features)\n",
    "    b = 0\n",
    "    n_errors = 0\n",
    "    weight_steps = []\n",
    "    total_pos_in_train = 0\n",
    "\n",
    "    # Adding this in for debug purposes to track the changes to the weight vectors on each\n",
    "    # round.\n",
    "    \n",
    "    # Average perceptron features\n",
    "    totalW = np.zeros(n_features)\n",
    "    totalB = 0;\n",
    "    updateCount = 0;\n",
    "    \n",
    "    # Now loop through each batch.\n",
    "    for batch_idx, (x, y) in tqdm(enumerate(train_dl), total=len(train_dl),):\n",
    "        \n",
    "        x_curr_np = x.numpy()\n",
    "        y_curr_np = y.numpy()\n",
    "\n",
    "        total_pos_in_train += (y_curr_np == 1).sum(axis=0)\n",
    "        \n",
    "\n",
    "        # Now perform the training/classification loop.\n",
    "        scores = x_curr_np @ w + b\n",
    "       \n",
    "        \n",
    "        y_pred = (scores > 0).astype(int)\n",
    "\n",
    "\n",
    "        # Now we vectorize the update to make this more efficient.\n",
    "        pred_error = y_curr_np - y_pred\n",
    "        n_errors += np.sum(np.abs(pred_error) != 0) # If the pred error is zero then it is correct.\n",
    "\n",
    "        # First append the previous weights to weight steps which will be used for debuging puprposes.\n",
    "        weight_steps.append((pred_error[:,None]*x_curr_np).sum(axis=0).copy())\n",
    "        \n",
    "        w += (pred_error[:,None]*x_curr_np).sum(axis=0) # Re-shape pred errors to update and only add\n",
    "                                                        # inccorect preds, axis=0 for rows.\n",
    "        b += pred_error.sum()\n",
    "\n",
    "        # Now print out the weights and bias updates every update if we are in debug mode.\n",
    "        \n",
    "\n",
    "    # Now once we are done training the result is the weights and biases.\n",
    "    return (w,b,n_errors,weight_steps.copy(),total_pos_in_train) # I am just copying to avoid weird cases due to mutability of list."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "705c0939-c452-47a5-a973-7007d82813a2",
   "metadata": {},
   "source": [
    "# Create the training and testing partitions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d92df580-200c-4b7d-943e-21adc213eb6d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train rows: 3,600\n",
      "dev rows: 900\n",
      "test rows: 500\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "train_df, test_df = train_test_split(education_data, train_size=0.9,random_state=seed)\n",
    "train_df,dev_df = train_test_split(train_df, train_size=0.8,random_state=seed)\n",
    "\n",
    "train_df.reset_index(inplace=True,drop=True)\n",
    "dev_df.reset_index(inplace=True,drop=True)\n",
    "test_df.reset_index(inplace=True,drop=True)\n",
    "\n",
    "\n",
    "print(f'train rows: {len(train_df.index):,}')\n",
    "print(f'dev rows: {len(dev_df.index):,}')\n",
    "print(f'test rows: {len(test_df.index):,}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "dae62e5f-bc8b-4386-99e1-bbf597d4d830",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "Pass/Fail Distribution in Datasets\n",
      "======================================================================\n",
      "\n",
      "Train Set:\n",
      "  Pass (1): 2105 (58.47%)\n",
      "  Fail (0): 1495 (41.53%)\n",
      "  Total: 3600\n",
      "\n",
      "Dev Set:\n",
      "  Pass (1): 555 (61.67%)\n",
      "  Fail (0): 345 (38.33%)\n",
      "  Total: 900\n",
      "\n",
      "Test Set:\n",
      "  Pass (1): 301 (60.20%)\n",
      "  Fail (0): 199 (39.80%)\n",
      "  Total: 500\n"
     ]
    }
   ],
   "source": [
    "# Check pass/fail distribution in train and dev datasets\n",
    "print(\"=\"*70)\n",
    "print(\"Pass/Fail Distribution in Datasets\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Train set distribution\n",
    "train_pass = (train_df['Grade'] == 1).sum()\n",
    "train_fail = (train_df['Grade'] == 0).sum()\n",
    "train_total = len(train_df)\n",
    "\n",
    "print(f\"\\nTrain Set:\")\n",
    "print(f\"  Pass (1): {train_pass} ({train_pass/train_total*100:.2f}%)\")\n",
    "print(f\"  Fail (0): {train_fail} ({train_fail/train_total*100:.2f}%)\")\n",
    "print(f\"  Total: {train_total}\")\n",
    "\n",
    "# Dev set distribution\n",
    "dev_pass = (dev_df['Grade'] == 1).sum()\n",
    "dev_fail = (dev_df['Grade'] == 0).sum()\n",
    "dev_total = len(dev_df)\n",
    "\n",
    "print(f\"\\nDev Set:\")\n",
    "print(f\"  Pass (1): {dev_pass} ({dev_pass/dev_total*100:.2f}%)\")\n",
    "print(f\"  Fail (0): {dev_fail} ({dev_fail/dev_total*100:.2f}%)\")\n",
    "print(f\"  Total: {dev_total}\")\n",
    "\n",
    "# Test set distribution\n",
    "test_pass = (test_df['Grade'] == 1).sum()\n",
    "test_fail = (test_df['Grade'] == 0).sum()\n",
    "test_total = len(test_df)\n",
    "\n",
    "print(f\"\\nTest Set:\")\n",
    "print(f\"  Pass (1): {test_pass} ({test_pass/test_total*100:.2f}%)\")\n",
    "print(f\"  Fail (0): {test_fail} ({test_fail/test_total*100:.2f}%)\")\n",
    "print(f\"  Total: {test_total}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93cec73b-a7a7-4b6c-ab49-0ddb949b5b3a",
   "metadata": {},
   "source": [
    "# Shave Columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "996653ec-f5ad-428b-96c9-f93578539051",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_features(data, column_name, exclude_cols, n):\n",
    "\n",
    "    data = data.drop(columns=exclude_cols)\n",
    "\n",
    "    corr_df = data.corr(method='pearson')[[column_name]]\n",
    "    corr_df = corr_df.drop(index=[column_name])\n",
    "    corr_df['Grade_Corr_Abs'] = corr_df[column_name].apply(lambda x: np.abs(x))\n",
    "    corr_df = corr_df.sort_values(by='Grade_Corr_Abs',ascending=False)\n",
    "    corr_df = corr_df[corr_df['Grade_Corr_Abs'] >= 0.1]\n",
    "    top_features = corr_df.head(n).index.tolist()\n",
    "    return top_features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a9940c6-6dc7-4917-be9d-ac08f8c50b4c",
   "metadata": {},
   "source": [
    "# Before Midterm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "8148d38e-4f37-4f1e-8028-7ad1e564ae1e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7cc60c4d42754e8c887cd5699c617bae",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/57 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b5fedef1416440ae9be43e88763c6c9b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/57 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3e4672b51bfd49a58c53e6395ce68297",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/57 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0d81a7a2585248bca06d1ecae7b9251d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/57 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ae7101f5581c490ca67c249d55d58141",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/57 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "468c6e7337fc4155b1b9d188aef2a4af",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/57 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ae257ace22af41a9bf856ecf171c1945",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/57 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f6c98a22640c405eb11bad69a0153838",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/57 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a289fe3c101f44b487bcfcfecd29a43e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/57 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1992a2d3ee874e06af73b4d9cbab4c9c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/57 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------Averaged Perceptron (10 perceptrons)------------------------------\n",
      "\n",
      "Averaged weight vector shape: [1278.50904045 -139.71191216 1375.66995692]\n",
      "Averaged bias value: -66.4000\n",
      "\n",
      "The number of correct preds was 555 for acc of 61.66666666666667%\n",
      "The number of pos preds was 900 and neg num was 0\n",
      "\n",
      "======================================================================\n",
      "Detailed Evaluation Metrics:\n",
      "======================================================================\n",
      "Accuracy: 61.67%\n",
      "Precision: 0.6167\n",
      "Recall: 1.0000\n",
      "F1-Score: 0.7629\n",
      "\n",
      "Confusion Matrix:\n",
      "                Predicted\n",
      "              Fail    Pass\n",
      "Actual Fail      0    345\n",
      "       Pass      0    555\n",
      "\n",
      "Predictions breakdown:\n",
      "  Predicted Fail (0): 0\n",
      "  Predicted Pass (1): 900\n",
      "  Actual Fail (0): 345\n",
      "  Actual Pass (1): 555\n"
     ]
    }
   ],
   "source": [
    "# Averaged Perceptron: Train 10 perceptrons and average their weights\n",
    "n_perceptrons = 10\n",
    "weight_vecs = []\n",
    "bias_vecs = []\n",
    "features_lst = get_features(education_data, 'Grade', ['Total_Score','Midterm_Score','Final_Score','Projects_Score'], 10)\n",
    "num_feat = len(features_lst)\n",
    "batch_size = 64\n",
    "shuffle = True\n",
    "for i in range(n_perceptrons):\n",
    "    train_ds = MyDataset(train_df, features_lst, 'Grade')\n",
    "    train_dl = DataLoader(train_ds, batch_size=batch_size, shuffle=shuffle)\n",
    "    \n",
    "    w_curr, b_curr, error_curr, weight_hist_curr, tot_train_pos_curr = train_perceptron(train_dl, num_feat, pos_class=1)\n",
    "    \n",
    "    weight_vecs.append(w_curr)\n",
    "    bias_vecs.append(b_curr)\n",
    "\n",
    "# Average the weights and biases\n",
    "w_avg = np.mean(weight_vecs, axis=0)\n",
    "b_avg = np.mean(bias_vecs, axis=0)\n",
    "\n",
    "print(f\"-------------------Averaged Perceptron (10 perceptrons)------------------------------\\n\")\n",
    "print(f\"Averaged weight vector shape: {w_avg}\")\n",
    "print(f\"Averaged bias value: {b_avg:.4f}\\n\")\n",
    "\n",
    "# Test on dev.\n",
    "X_dev_a = dev_df[features_lst].to_numpy()\n",
    "dev_y_true = dev_df['Grade'].to_numpy()\n",
    "dev_y_pred = ((X_dev_a @ w_avg + b_avg) > 0).astype(int)\n",
    "n_correct_dev = (dev_y_true==dev_y_pred).sum(axis=0)\n",
    "\n",
    "print(f\"The number of correct preds was {n_correct_dev} for acc of {(n_correct_dev/dev_y_true.shape[0])*100}%\")\n",
    "print(f\"The number of pos preds was {(dev_y_pred==1).sum(axis=0)} and neg num was {(dev_y_pred==0).sum(axis=0)}\")\n",
    "\n",
    "# Additional detailed metrics\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix\n",
    "\n",
    "accuracy = accuracy_score(dev_y_true, dev_y_pred)\n",
    "precision = precision_score(dev_y_true, dev_y_pred, zero_division=0)\n",
    "recall = recall_score(dev_y_true, dev_y_pred, zero_division=0)\n",
    "f1 = f1_score(dev_y_true, dev_y_pred, zero_division=0)\n",
    "cm = confusion_matrix(dev_y_true, dev_y_pred)\n",
    "\n",
    "print(f\"\\n{'='*70}\")\n",
    "print(\"Detailed Evaluation Metrics:\")\n",
    "print(f\"{'='*70}\")\n",
    "print(f\"Accuracy: {accuracy*100:.2f}%\")\n",
    "print(f\"Precision: {precision:.4f}\")\n",
    "print(f\"Recall: {recall:.4f}\")\n",
    "print(f\"F1-Score: {f1:.4f}\")\n",
    "\n",
    "print(f\"\\nConfusion Matrix:\")\n",
    "print(f\"                Predicted\")\n",
    "print(f\"              Fail    Pass\")\n",
    "print(f\"Actual Fail   {cm[0,0]:4d}   {cm[0,1]:4d}\")\n",
    "print(f\"       Pass   {cm[1,0]:4d}   {cm[1,1]:4d}\")\n",
    "\n",
    "print(f\"\\nPredictions breakdown:\")\n",
    "print(f\"  Predicted Fail (0): {(dev_y_pred==0).sum()}\")\n",
    "print(f\"  Predicted Pass (1): {(dev_y_pred==1).sum()}\")\n",
    "print(f\"  Actual Fail (0): {(dev_y_true==0).sum()}\")\n",
    "print(f\"  Actual Pass (1): {(dev_y_true==1).sum()}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e53ee25d-dc0c-4190-9dcd-2dc9fa9225dc",
   "metadata": {},
   "source": [
    "# After Midterm and before Final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "171a5f7a-2ee5-4a90-9165-0dba15049870",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f68c2085677e4d1b95a580e481dd4f71",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/57 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "002522d85b7648808dc98eea94515548",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/57 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a7415a3ecce649928d4e5152277572d1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/57 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b61ab07b36e2433bbf3fbb7fbc28b722",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/57 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "717250a22984421099f82876af4c6444",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/57 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7bec1e72306e4795b523397153dc977d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/57 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cb07d02770564da08a02cce63da4d219",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/57 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3053d8839c054224bec12cbc333ce50c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/57 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "60a7d5f346f44a3bbf872d91b380f029",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/57 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "00b260a4502043a7987a9b698a181f4a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/57 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------Averaged Perceptron (10 perceptrons)------------------------------\n",
      "\n",
      "Averaged weight vector shape: [  393.32006416  1149.93708382 -1437.70390778  1290.33992902]\n",
      "Averaged bias value: -85.1000\n",
      "\n",
      "The number of correct preds was 575 for acc of 63.888888888888886%\n",
      "The number of pos preds was 824 and neg num was 76\n",
      "\n",
      "======================================================================\n",
      "Detailed Evaluation Metrics:\n",
      "======================================================================\n",
      "Accuracy: 63.89%\n",
      "Precision: 0.6396\n",
      "Recall: 0.9495\n",
      "F1-Score: 0.7643\n",
      "\n",
      "Confusion Matrix:\n",
      "                Predicted\n",
      "              Fail    Pass\n",
      "Actual Fail     48    297\n",
      "       Pass     28    527\n",
      "\n",
      "Predictions breakdown:\n",
      "  Predicted Fail (0): 76\n",
      "  Predicted Pass (1): 824\n",
      "  Actual Fail (0): 345\n",
      "  Actual Pass (1): 555\n"
     ]
    }
   ],
   "source": [
    "# Averaged Perceptron: Train 10 perceptrons and average their weights\n",
    "n_perceptrons = 10\n",
    "weight_vecs = []\n",
    "bias_vecs = []\n",
    "features_lst = features_lst = get_features(education_data, 'Grade', ['Total_Score','Final_Score','Projects_Score'], 10)\n",
    "\n",
    "num_feat = len(features_lst)\n",
    "\n",
    "for i in range(n_perceptrons):\n",
    "    train_ds = MyDataset(train_df, features_lst, 'Grade')\n",
    "    train_dl = DataLoader(train_ds, batch_size=batch_size, shuffle=shuffle)\n",
    "    \n",
    "    w_curr, b_curr, error_curr, weight_hist_curr, tot_train_pos_curr = train_perceptron(train_dl, num_feat, pos_class=1)\n",
    "    \n",
    "    weight_vecs.append(w_curr)\n",
    "    bias_vecs.append(b_curr)\n",
    "\n",
    "# Average the weights and biases\n",
    "w_avg = np.mean(weight_vecs, axis=0)\n",
    "b_avg = np.mean(bias_vecs, axis=0)\n",
    "\n",
    "print(f\"-------------------Averaged Perceptron (10 perceptrons)------------------------------\\n\")\n",
    "print(f\"Averaged weight vector shape: {w_avg}\")\n",
    "print(f\"Averaged bias value: {b_avg:.4f}\\n\")\n",
    "\n",
    "# Test on dev.\n",
    "X_dev_a = dev_df[features_lst].to_numpy()\n",
    "dev_y_true = dev_df['Grade'].to_numpy()\n",
    "dev_y_pred = ((X_dev_a @ w_avg + b_avg) > 0).astype(int)\n",
    "n_correct_dev = (dev_y_true==dev_y_pred).sum(axis=0)\n",
    "\n",
    "print(f\"The number of correct preds was {n_correct_dev} for acc of {(n_correct_dev/dev_y_true.shape[0])*100}%\")\n",
    "print(f\"The number of pos preds was {(dev_y_pred==1).sum(axis=0)} and neg num was {(dev_y_pred==0).sum(axis=0)}\")\n",
    "\n",
    "# Additional detailed metrics\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix\n",
    "\n",
    "accuracy = accuracy_score(dev_y_true, dev_y_pred)\n",
    "precision = precision_score(dev_y_true, dev_y_pred, zero_division=0)\n",
    "recall = recall_score(dev_y_true, dev_y_pred, zero_division=0)\n",
    "f1 = f1_score(dev_y_true, dev_y_pred, zero_division=0)\n",
    "cm = confusion_matrix(dev_y_true, dev_y_pred)\n",
    "\n",
    "print(f\"\\n{'='*70}\")\n",
    "print(\"Detailed Evaluation Metrics:\")\n",
    "print(f\"{'='*70}\")\n",
    "print(f\"Accuracy: {accuracy*100:.2f}%\")\n",
    "print(f\"Precision: {precision:.4f}\")\n",
    "print(f\"Recall: {recall:.4f}\")\n",
    "print(f\"F1-Score: {f1:.4f}\")\n",
    "\n",
    "print(f\"\\nConfusion Matrix:\")\n",
    "print(f\"                Predicted\")\n",
    "print(f\"              Fail    Pass\")\n",
    "print(f\"Actual Fail   {cm[0,0]:4d}   {cm[0,1]:4d}\")\n",
    "print(f\"       Pass   {cm[1,0]:4d}   {cm[1,1]:4d}\")\n",
    "\n",
    "print(f\"\\nPredictions breakdown:\")\n",
    "print(f\"  Predicted Fail (0): {(dev_y_pred==0).sum()}\")\n",
    "print(f\"  Predicted Pass (1): {(dev_y_pred==1).sum()}\")\n",
    "print(f\"  Actual Fail (0): {(dev_y_true==0).sum()}\")\n",
    "print(f\"  Actual Pass (1): {(dev_y_true==1).sum()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80d8a928-6a3c-4c0c-bc9a-523a88141e52",
   "metadata": {},
   "source": [
    "# After Final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "12eafc0b-00f4-422e-9f14-1a60c78849d6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ab30119410c34f22a9fdbffd4efcfafd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/57 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9d456206cf604ba28bdae918f08ef19a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/57 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "12aeea5a20544535a17102e7da9eb9ab",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/57 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e795f6da2dd04ba08538cb6c5142802c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/57 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "85e3b32f62f848a28361bf4cc500ac12",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/57 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "528f115dd2d2418885aac0e7e95ec0f2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/57 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d4b4c4b443134b07ba0eb24a060b4c79",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/57 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a28f3522faa84a97b677374b2d383f88",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/57 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "38990c5629574188bb8f9663c362f1f4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/57 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f2d59adb05a347048bbc0e3c8a9070a3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/57 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------Averaged Perceptron (10 perceptrons)------------------------------\n",
      "\n",
      "Averaged weight vector shape: [ 5089.84199448  3209.22502289 -1626.95300293  -294.45893288\n",
      " -3480.15794106   993.59990144]\n",
      "Averaged bias value: -115.7000\n",
      "\n",
      "The number of correct preds was 564 for acc of 62.66666666666667%\n",
      "The number of pos preds was 891 and neg num was 9\n",
      "\n",
      "======================================================================\n",
      "Detailed Evaluation Metrics:\n",
      "======================================================================\n",
      "Accuracy: 62.67%\n",
      "Precision: 0.6229\n",
      "Recall: 1.0000\n",
      "F1-Score: 0.7676\n",
      "\n",
      "Confusion Matrix:\n",
      "                Predicted\n",
      "              Fail    Pass\n",
      "Actual Fail      9    336\n",
      "       Pass      0    555\n",
      "\n",
      "Predictions breakdown:\n",
      "  Predicted Fail (0): 9\n",
      "  Predicted Pass (1): 891\n",
      "  Actual Fail (0): 345\n",
      "  Actual Pass (1): 555\n"
     ]
    }
   ],
   "source": [
    "# Averaged Perceptron: Train 10 perceptrons and average their weights\n",
    "n_perceptrons = 10\n",
    "weight_vecs = []\n",
    "bias_vecs = []\n",
    "features_lst = features_lst = get_features(education_data, 'Grade', ['Total_Score'], 10)\n",
    "\n",
    "num_feat = len(features_lst)\n",
    "\n",
    "for i in range(n_perceptrons):\n",
    "    train_ds = MyDataset(train_df, features_lst, 'Grade')\n",
    "    train_dl = DataLoader(train_ds, batch_size=batch_size, shuffle=shuffle)\n",
    "    \n",
    "    w_curr, b_curr, error_curr, weight_hist_curr, tot_train_pos_curr = train_perceptron(train_dl, num_feat, pos_class=1)\n",
    "    \n",
    "    weight_vecs.append(w_curr)\n",
    "    bias_vecs.append(b_curr)\n",
    "\n",
    "# Average the weights and biases\n",
    "w_avg = np.mean(weight_vecs, axis=0)\n",
    "b_avg = np.mean(bias_vecs, axis=0)\n",
    "\n",
    "print(f\"-------------------Averaged Perceptron (10 perceptrons)------------------------------\\n\")\n",
    "print(f\"Averaged weight vector shape: {w_avg}\")\n",
    "print(f\"Averaged bias value: {b_avg:.4f}\\n\")\n",
    "\n",
    "# Test on dev.\n",
    "X_dev_a = dev_df[features_lst].to_numpy()\n",
    "dev_y_true = dev_df['Grade'].to_numpy()\n",
    "dev_y_pred = ((X_dev_a @ w_avg + b_avg) > 0).astype(int)\n",
    "n_correct_dev = (dev_y_true==dev_y_pred).sum(axis=0)\n",
    "\n",
    "print(f\"The number of correct preds was {n_correct_dev} for acc of {(n_correct_dev/dev_y_true.shape[0])*100}%\")\n",
    "print(f\"The number of pos preds was {(dev_y_pred==1).sum(axis=0)} and neg num was {(dev_y_pred==0).sum(axis=0)}\")\n",
    "\n",
    "# Additional detailed metrics\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix\n",
    "\n",
    "accuracy = accuracy_score(dev_y_true, dev_y_pred)\n",
    "precision = precision_score(dev_y_true, dev_y_pred, zero_division=0)\n",
    "recall = recall_score(dev_y_true, dev_y_pred, zero_division=0)\n",
    "f1 = f1_score(dev_y_true, dev_y_pred, zero_division=0)\n",
    "cm = confusion_matrix(dev_y_true, dev_y_pred)\n",
    "\n",
    "print(f\"\\n{'='*70}\")\n",
    "print(\"Detailed Evaluation Metrics:\")\n",
    "print(f\"{'='*70}\")\n",
    "print(f\"Accuracy: {accuracy*100:.2f}%\")\n",
    "print(f\"Precision: {precision:.4f}\")\n",
    "print(f\"Recall: {recall:.4f}\")\n",
    "print(f\"F1-Score: {f1:.4f}\")\n",
    "\n",
    "print(f\"\\nConfusion Matrix:\")\n",
    "print(f\"                Predicted\")\n",
    "print(f\"              Fail    Pass\")\n",
    "print(f\"Actual Fail   {cm[0,0]:4d}   {cm[0,1]:4d}\")\n",
    "print(f\"       Pass   {cm[1,0]:4d}   {cm[1,1]:4d}\")\n",
    "\n",
    "print(f\"\\nPredictions breakdown:\")\n",
    "print(f\"  Predicted Fail (0): {(dev_y_pred==0).sum()}\")\n",
    "print(f\"  Predicted Pass (1): {(dev_y_pred==1).sum()}\")\n",
    "print(f\"  Actual Fail (0): {(dev_y_true==0).sum()}\")\n",
    "print(f\"  Actual Pass (1): {(dev_y_true==1).sum()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "71f40813-920e-4707-bfed-f2398d86c486",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15 Examples of False Positives (Predicted Pass, Actual Fail):\n",
      "    Attendance (%)  Extracurricular_Activities  Midterm_Score  Final_Score  \\\n",
      "1            92.68                           1          60.33        70.99   \n",
      "8            70.32                           1          41.14        83.66   \n",
      "16           68.04                           1          57.49        42.38   \n",
      "19           52.96                           0          78.38        55.22   \n",
      "20           68.14                           1          95.82        56.38   \n",
      "22           72.90                           1          97.19        46.40   \n",
      "23           87.30                           0          75.40        49.35   \n",
      "27           96.62                           0          79.96        50.66   \n",
      "31           66.87                           0          72.25        88.65   \n",
      "32           68.47                           1          57.07        60.64   \n",
      "35           88.60                           1          51.46        43.25   \n",
      "36           57.46                           0          47.28        51.52   \n",
      "37           65.60                           0          76.57        75.55   \n",
      "40           56.27                           1          68.07        42.62   \n",
      "41           93.88                           1          78.46        50.27   \n",
      "\n",
      "    Assignments_Avg  Quizzes_Avg  Participation_Score  Projects_Score  \\\n",
      "1             85.67        55.46                  5.7           76.40   \n",
      "8             66.76        61.46                 68.2           62.64   \n",
      "16            77.73        81.72                 55.6           69.32   \n",
      "19            60.21        76.98                 82.2           69.37   \n",
      "20            69.11        74.48                 64.0           56.80   \n",
      "22            64.63        84.68                  4.5           59.90   \n",
      "23            91.45        70.60                 50.5           52.87   \n",
      "27            77.49        54.35                 36.4           71.42   \n",
      "31            54.94        77.86                 13.3           66.85   \n",
      "32            53.66        85.30                 26.5           74.31   \n",
      "35            73.85        79.19                 49.8           57.23   \n",
      "36            57.06        88.44                 72.3           51.13   \n",
      "37            54.99        54.26                 21.3           53.73   \n",
      "40            67.12        61.10                 86.7           62.50   \n",
      "41            62.89        62.25                 74.8           53.17   \n",
      "\n",
      "    Stress_Level (1-10)  Sleep_Hours_per_Night  Grade  \n",
      "1                     3                    8.2      0  \n",
      "8                     8                    4.4      0  \n",
      "16                    4                    7.3      0  \n",
      "19                    1                    8.0      0  \n",
      "20                    7                    6.9      0  \n",
      "22                    3                    7.1      0  \n",
      "23                   10                    4.8      0  \n",
      "27                    5                    8.3      0  \n",
      "31                    6                    6.2      0  \n",
      "32                   10                    8.7      0  \n",
      "35                   10                    8.2      0  \n",
      "36                    1                    6.4      0  \n",
      "37                    8                    7.3      0  \n",
      "40                    4                    7.5      0  \n",
      "41                    1                    4.3      0  \n",
      "\n",
      "10 Examples of False Negatives (Predicted Fail, Actual Pass):\n",
      "Empty DataFrame\n",
      "Columns: [Attendance (%), Extracurricular_Activities, Midterm_Score, Final_Score, Assignments_Avg, Quizzes_Avg, Participation_Score, Projects_Score, Stress_Level (1-10), Sleep_Hours_per_Night, Grade]\n",
      "Index: []\n"
     ]
    }
   ],
   "source": [
    "# Find False Positives (FP): Predicted Pass (1) but actual Fail (0)\n",
    "false_pos_indices = np.where((dev_y_pred == 1) & (dev_y_true == 0))[0]\n",
    "false_pos_examples = dev_df.iloc[false_pos_indices]\n",
    "\n",
    "# Find False Negatives (FN): Predicted Fail (0) but actual Pass (1)\n",
    "false_neg_indices = np.where((dev_y_pred == 0) & (dev_y_true == 1))[0]\n",
    "false_neg_examples = dev_df.iloc[false_neg_indices]\n",
    "\n",
    "# Get top 15 false positives and top 10 false negatives\n",
    "false_pos_examples_top_15 = false_pos_examples.head(15)\n",
    "false_neg_examples_top_10 = false_neg_examples.head(10)\n",
    "\n",
    "# Print out the examples\n",
    "print(\"15 Examples of False Positives (Predicted Pass, Actual Fail):\")\n",
    "print(false_pos_examples_top_15[['Attendance (%)', 'Extracurricular_Activities', 'Midterm_Score', 'Final_Score', \n",
    "                                  'Assignments_Avg', 'Quizzes_Avg', 'Participation_Score', 'Projects_Score', \n",
    "                                  'Stress_Level (1-10)', 'Sleep_Hours_per_Night', 'Grade']])\n",
    "\n",
    "print(\"\\n10 Examples of False Negatives (Predicted Fail, Actual Pass):\")\n",
    "print(false_neg_examples_top_10[['Attendance (%)', 'Extracurricular_Activities', 'Midterm_Score', 'Final_Score', \n",
    "                                  'Assignments_Avg', 'Quizzes_Avg', 'Participation_Score', 'Projects_Score', \n",
    "                                  'Stress_Level (1-10)', 'Sleep_Hours_per_Night', 'Grade']])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3d9e2fb-ac0b-46aa-bda3-7f322dca0d6e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
