{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a136d87f-81e8-4e65-9d30-75fcd2c6ff7b",
   "metadata": {},
   "source": [
    "# Performing needed imports and boilder plate code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "472cc83c-1425-47ed-b290-9039207e03ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "from tqdm.notebook import tqdm\n",
    "import pandas as pd\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "# set this variable to a number to be used as the random seed\n",
    "# or to None if you don't want to set a random seed\n",
    "seed = 1234\n",
    "\n",
    "if seed is not None:\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.manual_seed(seed)\n",
    "        torch.cuda.manual_seed_all(seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c7b032e-e4dc-4cb0-96e2-5b5acaeb463c",
   "metadata": {},
   "source": [
    "# Copied over data cleaning steps from our data cleaning notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "5c4c7721-2d24-48e9-bd40-e66aea329f0f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_649959/1122780081.py:6: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  education_data['Gender'] = education_data['Gender'].replace({'Male': 1, 'Female': 0}).astype(int)\n",
      "/tmp/ipykernel_649959/1122780081.py:7: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  education_data['Internet_Access_at_Home'] = education_data['Internet_Access_at_Home'].replace({'Yes': 1, 'No': 0}).astype(int)\n",
      "/tmp/ipykernel_649959/1122780081.py:8: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  education_data['Extracurricular_Activities'] = education_data['Extracurricular_Activities'].replace({'Yes': 1, 'No': 0}).astype(int)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Gender</th>\n",
       "      <th>Age</th>\n",
       "      <th>Department</th>\n",
       "      <th>department index</th>\n",
       "      <th>Attendance (%)</th>\n",
       "      <th>Midterm_Score</th>\n",
       "      <th>Final_Score</th>\n",
       "      <th>Assignments_Avg</th>\n",
       "      <th>Quizzes_Avg</th>\n",
       "      <th>Participation_Score</th>\n",
       "      <th>Projects_Score</th>\n",
       "      <th>Total_Score</th>\n",
       "      <th>Grade</th>\n",
       "      <th>Study_Hours_per_Week</th>\n",
       "      <th>Extracurricular_Activities</th>\n",
       "      <th>Internet_Access_at_Home</th>\n",
       "      <th>Family_Income_Level</th>\n",
       "      <th>Stress_Level (1-10)</th>\n",
       "      <th>Sleep_Hours_per_Night</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>22</td>\n",
       "      <td>Mathematics</td>\n",
       "      <td>0</td>\n",
       "      <td>97.36</td>\n",
       "      <td>40.61</td>\n",
       "      <td>59.61</td>\n",
       "      <td>73.69</td>\n",
       "      <td>53.17</td>\n",
       "      <td>73.4</td>\n",
       "      <td>62.84</td>\n",
       "      <td>59.8865</td>\n",
       "      <td>0</td>\n",
       "      <td>10.3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>5.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>18</td>\n",
       "      <td>Business</td>\n",
       "      <td>1</td>\n",
       "      <td>97.71</td>\n",
       "      <td>57.27</td>\n",
       "      <td>74.00</td>\n",
       "      <td>74.23</td>\n",
       "      <td>98.23</td>\n",
       "      <td>88.0</td>\n",
       "      <td>98.23</td>\n",
       "      <td>81.9170</td>\n",
       "      <td>1</td>\n",
       "      <td>27.1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>4.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>24</td>\n",
       "      <td>Engineering</td>\n",
       "      <td>2</td>\n",
       "      <td>99.52</td>\n",
       "      <td>41.84</td>\n",
       "      <td>63.85</td>\n",
       "      <td>85.85</td>\n",
       "      <td>50.00</td>\n",
       "      <td>4.7</td>\n",
       "      <td>91.22</td>\n",
       "      <td>67.7170</td>\n",
       "      <td>0</td>\n",
       "      <td>12.4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>6.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>24</td>\n",
       "      <td>Engineering</td>\n",
       "      <td>2</td>\n",
       "      <td>90.38</td>\n",
       "      <td>45.65</td>\n",
       "      <td>44.44</td>\n",
       "      <td>68.10</td>\n",
       "      <td>66.27</td>\n",
       "      <td>4.2</td>\n",
       "      <td>55.48</td>\n",
       "      <td>51.6535</td>\n",
       "      <td>0</td>\n",
       "      <td>25.5</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>4.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>23</td>\n",
       "      <td>CS</td>\n",
       "      <td>3</td>\n",
       "      <td>59.41</td>\n",
       "      <td>53.13</td>\n",
       "      <td>61.77</td>\n",
       "      <td>67.66</td>\n",
       "      <td>83.98</td>\n",
       "      <td>64.3</td>\n",
       "      <td>87.43</td>\n",
       "      <td>71.4030</td>\n",
       "      <td>1</td>\n",
       "      <td>13.3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>4.5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Gender  Age   Department  department index  Attendance (%)  Midterm_Score  \\\n",
       "0       0   22  Mathematics                 0           97.36          40.61   \n",
       "1       1   18     Business                 1           97.71          57.27   \n",
       "2       1   24  Engineering                 2           99.52          41.84   \n",
       "3       0   24  Engineering                 2           90.38          45.65   \n",
       "4       0   23           CS                 3           59.41          53.13   \n",
       "\n",
       "   Final_Score  Assignments_Avg  Quizzes_Avg  Participation_Score  \\\n",
       "0        59.61            73.69        53.17                 73.4   \n",
       "1        74.00            74.23        98.23                 88.0   \n",
       "2        63.85            85.85        50.00                  4.7   \n",
       "3        44.44            68.10        66.27                  4.2   \n",
       "4        61.77            67.66        83.98                 64.3   \n",
       "\n",
       "   Projects_Score  Total_Score  Grade  Study_Hours_per_Week  \\\n",
       "0           62.84      59.8865      0                  10.3   \n",
       "1           98.23      81.9170      1                  27.1   \n",
       "2           91.22      67.7170      0                  12.4   \n",
       "3           55.48      51.6535      0                  25.5   \n",
       "4           87.43      71.4030      1                  13.3   \n",
       "\n",
       "   Extracurricular_Activities  Internet_Access_at_Home  Family_Income_Level  \\\n",
       "0                           1                        0                    2   \n",
       "1                           0                        0                    1   \n",
       "2                           1                        0                    1   \n",
       "3                           0                        1                    1   \n",
       "4                           1                        0                    2   \n",
       "\n",
       "   Stress_Level (1-10)  Sleep_Hours_per_Night  \n",
       "0                    1                    5.9  \n",
       "1                    4                    4.3  \n",
       "2                    9                    6.1  \n",
       "3                    8                    4.9  \n",
       "4                    6                    4.5  "
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "education_data = pd.read_csv('students_clean.csv')\n",
    "\n",
    "\n",
    "education_data.drop('Parent_Education_Level', axis=1, inplace=True) \n",
    "\n",
    "education_data['Gender'] = education_data['Gender'].replace({'Male': 1, 'Female': 0}).astype(int)\n",
    "education_data['Internet_Access_at_Home'] = education_data['Internet_Access_at_Home'].replace({'Yes': 1, 'No': 0}).astype(int)\n",
    "education_data['Extracurricular_Activities'] = education_data['Extracurricular_Activities'].replace({'Yes': 1, 'No': 0}).astype(int)\n",
    "\n",
    "\n",
    "# Low = 1, Medium = 2, High = 3\n",
    "mapper = {'low': 1, 'medium': 2, 'high': 3}\n",
    "\n",
    "education_data['Family_Income_Level'] = (\n",
    "    education_data['Family_Income_Level']\n",
    "      .astype(str)                  # works even if the value is already 1/2/3 or NaN\n",
    "      .str.strip().str.lower()\n",
    "      .map(mapper)                  # returns NaN where no mapping found\n",
    "      .fillna(education_data['Family_Income_Level'])  # keepin the original numeric/blank entries\n",
    "      .astype('Int64')              #  nullable integer dtype\n",
    ")\n",
    "\n",
    "labels = open('departments.txt').read().splitlines()\n",
    "department_mapping = {name: index for index, name in enumerate(labels)}\n",
    "department_indices = education_data['Department'].map(department_mapping)\n",
    "education_data.insert(3, 'department index', department_indices)\n",
    "\n",
    "mapper = {'A': 1, 'B': 1, 'C': 1, 'D':0,'F':0}\n",
    "\n",
    "education_data['Grade'] = (\n",
    "    education_data['Grade']\n",
    "      .astype(str)              # convert everything to string\n",
    "      .str.strip().str.upper()  # remove spaces and standardize to uppercase\n",
    "      .map(mapper)              # map letters to numbers\n",
    ")\n",
    "\n",
    "education_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd384bde-8776-4715-be27-1e4987b0464a",
   "metadata": {},
   "source": [
    "# Now defining our data loader and perceptron"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "d7ae6abf-6783-4b0e-a3e9-7b40b2700d14",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset\n",
    "import torch\n",
    "\n",
    "class MyDataset(Dataset):\n",
    "    def __init__(self, df, feature_cols, target_col):\n",
    "        self.df = df\n",
    "        self.feature_cols = feature_cols\n",
    "        self.target_col = target_col\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        row = self.df.iloc[index]\n",
    "        x = torch.tensor(row[self.feature_cols].to_numpy(dtype=np.float32), dtype=torch.float32)\n",
    "        y = torch.tensor(row[self.target_col], dtype=torch.long)  # long for classification\n",
    "        return x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "7220d113-16ca-4e46-b771-b8fd567195e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_perceptron(train_dl, n_features, pos_class):\n",
    "    # First initialize the model.\n",
    "    w = np.zeros(n_features)\n",
    "    b = 0\n",
    "    n_errors = 0\n",
    "    weight_steps = []\n",
    "    total_pos_in_train = 0\n",
    "\n",
    "    # Adding this in for debug purposes to track the changes to the weight vectors on each\n",
    "    # round.\n",
    "    \n",
    "    # Average perceptron features\n",
    "    totalW = np.zeros(n_features)\n",
    "    totalB = 0;\n",
    "    updateCount = 0;\n",
    "    \n",
    "    # Now loop through each batch.\n",
    "    for batch_idx, (x, y) in tqdm(enumerate(train_dl), total=len(train_dl),):\n",
    "        \n",
    "        x_curr_np = x.numpy()\n",
    "        y_curr_np = y.numpy()\n",
    "\n",
    "        total_pos_in_train += (y_curr_np == 1).sum(axis=0)\n",
    "        \n",
    "\n",
    "        # Now perform the training/classification loop.\n",
    "        scores = x_curr_np @ w + b\n",
    "       \n",
    "        \n",
    "        y_pred = (scores > 0).astype(int)\n",
    "\n",
    "\n",
    "        # Now we vectorize the update to make this more efficient.\n",
    "        pred_error = y_curr_np - y_pred\n",
    "        n_errors += np.sum(np.abs(pred_error) != 0) # If the pred error is zero then it is correct.\n",
    "\n",
    "        # First append the previous weights to weight steps which will be used for debuging puprposes.\n",
    "        weight_steps.append((pred_error[:,None]*x_curr_np).sum(axis=0).copy())\n",
    "        \n",
    "        w += (pred_error[:,None]*x_curr_np).sum(axis=0) # Re-shape pred errors to update and only add\n",
    "                                                        # inccorect preds, axis=0 for rows.\n",
    "        b += pred_error.sum()\n",
    "\n",
    "        # Now print out the weights and bias updates every update if we are in debug mode.\n",
    "        \n",
    "\n",
    "    # Now once we are done training the result is the weights and biases.\n",
    "    return (w,b,n_errors,weight_steps.copy(),total_pos_in_train) # I am just copying to avoid weird cases due to mutability of list."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "705c0939-c452-47a5-a973-7007d82813a2",
   "metadata": {},
   "source": [
    "# Create the training and testing partitions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "d92df580-200c-4b7d-943e-21adc213eb6d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train rows: 3,600\n",
      "dev rows: 900\n",
      "test rows: 500\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "train_df, test_df = train_test_split(education_data, train_size=0.9,random_state=seed)\n",
    "train_df,dev_df = train_test_split(train_df, train_size=0.8,random_state=seed)\n",
    "\n",
    "train_df.reset_index(inplace=True,drop=True)\n",
    "dev_df.reset_index(inplace=True,drop=True)\n",
    "test_df.reset_index(inplace=True,drop=True)\n",
    "\n",
    "\n",
    "print(f'train rows: {len(train_df.index):,}')\n",
    "print(f'dev rows: {len(dev_df.index):,}')\n",
    "print(f'test rows: {len(test_df.index):,}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "dae62e5f-bc8b-4386-99e1-bbf597d4d830",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "Pass/Fail Distribution in Datasets\n",
      "======================================================================\n",
      "\n",
      "Train Set:\n",
      "  Pass (1): 2105 (58.47%)\n",
      "  Fail (0): 1495 (41.53%)\n",
      "  Total: 3600\n",
      "\n",
      "Dev Set:\n",
      "  Pass (1): 555 (61.67%)\n",
      "  Fail (0): 345 (38.33%)\n",
      "  Total: 900\n",
      "\n",
      "Test Set:\n",
      "  Pass (1): 301 (60.20%)\n",
      "  Fail (0): 199 (39.80%)\n",
      "  Total: 500\n"
     ]
    }
   ],
   "source": [
    "# Check pass/fail distribution in train and dev datasets\n",
    "print(\"=\"*70)\n",
    "print(\"Pass/Fail Distribution in Datasets\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Train set distribution\n",
    "train_pass = (train_df['Grade'] == 1).sum()\n",
    "train_fail = (train_df['Grade'] == 0).sum()\n",
    "train_total = len(train_df)\n",
    "\n",
    "print(f\"\\nTrain Set:\")\n",
    "print(f\"  Pass (1): {train_pass} ({train_pass/train_total*100:.2f}%)\")\n",
    "print(f\"  Fail (0): {train_fail} ({train_fail/train_total*100:.2f}%)\")\n",
    "print(f\"  Total: {train_total}\")\n",
    "\n",
    "# Dev set distribution\n",
    "dev_pass = (dev_df['Grade'] == 1).sum()\n",
    "dev_fail = (dev_df['Grade'] == 0).sum()\n",
    "dev_total = len(dev_df)\n",
    "\n",
    "print(f\"\\nDev Set:\")\n",
    "print(f\"  Pass (1): {dev_pass} ({dev_pass/dev_total*100:.2f}%)\")\n",
    "print(f\"  Fail (0): {dev_fail} ({dev_fail/dev_total*100:.2f}%)\")\n",
    "print(f\"  Total: {dev_total}\")\n",
    "\n",
    "# Test set distribution\n",
    "test_pass = (test_df['Grade'] == 1).sum()\n",
    "test_fail = (test_df['Grade'] == 0).sum()\n",
    "test_total = len(test_df)\n",
    "\n",
    "print(f\"\\nTest Set:\")\n",
    "print(f\"  Pass (1): {test_pass} ({test_pass/test_total*100:.2f}%)\")\n",
    "print(f\"  Fail (0): {test_fail} ({test_fail/test_total*100:.2f}%)\")\n",
    "print(f\"  Total: {test_total}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a9940c6-6dc7-4917-be9d-ac08f8c50b4c",
   "metadata": {},
   "source": [
    "# Before Midterm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "8148d38e-4f37-4f1e-8028-7ad1e564ae1e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "40c5010243434a23b47506ed7b0b611e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/720 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "887ffbb1610d45c790ef9eaac11acef9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/720 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a418ffb5fe064c48a2624cc31aaafd4d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/720 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "08cb8e3579fb4132af6c3810c19961b3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/720 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "06111a65ca8e4330b77c5348ff5a043f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/720 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "482dfc2244ed44c394f384b923417b3c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/720 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "765c163d510c4e78b23bf33a1a230950",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/720 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d665a482e0f341ac9740b038c80953bf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/720 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0cbfed389af941da9d6956e1b803e6c1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/720 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "32ac5d09112940ca84427e6a046e38a1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/720 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------Averaged Perceptron (10 perceptrons)------------------------------\n",
      "\n",
      "Averaged weight vector shape: [-408.872929    309.21100693   94.43710022  228.55991605   -2.3\n",
      " -175.9        -258.40000601  -33.9       ]\n",
      "Averaged bias value: -48.4000\n",
      "\n",
      "The number of correct preds was 566 for acc of 62.88888888888889%\n",
      "The number of pos preds was 693 and neg num was 207\n",
      "\n",
      "======================================================================\n",
      "Detailed Evaluation Metrics:\n",
      "======================================================================\n",
      "Accuracy: 62.89%\n",
      "Precision: 0.6595\n",
      "Recall: 0.8234\n",
      "F1-Score: 0.7324\n",
      "\n",
      "Confusion Matrix:\n",
      "                Predicted\n",
      "              Fail    Pass\n",
      "Actual Fail    109    236\n",
      "       Pass     98    457\n",
      "\n",
      "Predictions breakdown:\n",
      "  Predicted Fail (0): 207\n",
      "  Predicted Pass (1): 693\n",
      "  Actual Fail (0): 345\n",
      "  Actual Pass (1): 555\n"
     ]
    }
   ],
   "source": [
    "# Averaged Perceptron: Train 10 perceptrons and average their weights\n",
    "n_perceptrons = 10\n",
    "weight_vecs = []\n",
    "bias_vecs = []\n",
    "features_lst = ['Attendance (%)', \\\n",
    "       'Assignments_Avg', 'Quizzes_Avg', \\\n",
    "       'Participation_Score', 'Internet_Access_at_Home', \\\n",
    "       'Stress_Level (1-10)', \\\n",
    "       'Sleep_Hours_per_Night', 'Extracurricular_Activities']\n",
    "num_feat = len(features_lst)\n",
    "\n",
    "for i in range(n_perceptrons):\n",
    "    train_ds = MyDataset(train_df, features_lst, 'Grade')\n",
    "    train_dl = DataLoader(train_ds, batch_size=batch_size, shuffle=shuffle)\n",
    "    \n",
    "    w_curr, b_curr, error_curr, weight_hist_curr, tot_train_pos_curr = train_perceptron(train_dl, num_feat, pos_class=1)\n",
    "    \n",
    "    weight_vecs.append(w_curr)\n",
    "    bias_vecs.append(b_curr)\n",
    "\n",
    "# Average the weights and biases\n",
    "w_avg = np.mean(weight_vecs, axis=0)\n",
    "b_avg = np.mean(bias_vecs, axis=0)\n",
    "\n",
    "print(f\"-------------------Averaged Perceptron (10 perceptrons)------------------------------\\n\")\n",
    "print(f\"Averaged weight vector shape: {w_avg}\")\n",
    "print(f\"Averaged bias value: {b_avg:.4f}\\n\")\n",
    "\n",
    "# Test on dev.\n",
    "X_dev_a = dev_df[features_lst].to_numpy()\n",
    "dev_y_true = dev_df['Grade'].to_numpy()\n",
    "dev_y_pred = ((X_dev_a @ w_avg + b_avg) > 0).astype(int)\n",
    "n_correct_dev = (dev_y_true==dev_y_pred).sum(axis=0)\n",
    "\n",
    "print(f\"The number of correct preds was {n_correct_dev} for acc of {(n_correct_dev/dev_y_true.shape[0])*100}%\")\n",
    "print(f\"The number of pos preds was {(dev_y_pred==1).sum(axis=0)} and neg num was {(dev_y_pred==0).sum(axis=0)}\")\n",
    "\n",
    "# Additional detailed metrics\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix\n",
    "\n",
    "accuracy = accuracy_score(dev_y_true, dev_y_pred)\n",
    "precision = precision_score(dev_y_true, dev_y_pred, zero_division=0)\n",
    "recall = recall_score(dev_y_true, dev_y_pred, zero_division=0)\n",
    "f1 = f1_score(dev_y_true, dev_y_pred, zero_division=0)\n",
    "cm = confusion_matrix(dev_y_true, dev_y_pred)\n",
    "\n",
    "print(f\"\\n{'='*70}\")\n",
    "print(\"Detailed Evaluation Metrics:\")\n",
    "print(f\"{'='*70}\")\n",
    "print(f\"Accuracy: {accuracy*100:.2f}%\")\n",
    "print(f\"Precision: {precision:.4f}\")\n",
    "print(f\"Recall: {recall:.4f}\")\n",
    "print(f\"F1-Score: {f1:.4f}\")\n",
    "\n",
    "print(f\"\\nConfusion Matrix:\")\n",
    "print(f\"                Predicted\")\n",
    "print(f\"              Fail    Pass\")\n",
    "print(f\"Actual Fail   {cm[0,0]:4d}   {cm[0,1]:4d}\")\n",
    "print(f\"       Pass   {cm[1,0]:4d}   {cm[1,1]:4d}\")\n",
    "\n",
    "print(f\"\\nPredictions breakdown:\")\n",
    "print(f\"  Predicted Fail (0): {(dev_y_pred==0).sum()}\")\n",
    "print(f\"  Predicted Pass (1): {(dev_y_pred==1).sum()}\")\n",
    "print(f\"  Actual Fail (0): {(dev_y_true==0).sum()}\")\n",
    "print(f\"  Actual Pass (1): {(dev_y_true==1).sum()}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e53ee25d-dc0c-4190-9dcd-2dc9fa9225dc",
   "metadata": {},
   "source": [
    "# After Midterm and before Final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "171a5f7a-2ee5-4a90-9165-0dba15049870",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "57192d1ef5ed40e48cbe4d03b0abce47",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/720 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "95e7e567b39b4e08ab2b1bced1b12dc0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/720 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "55e28e8b0f5f43bf87067f53616d2c7d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/720 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f16a78aa9c204f67a7995902b01e6b0e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/720 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9046ef3cb1a44bab8b8ebeffd208cc46",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/720 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "71444a33a1ab45018d696062fdd53aff",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/720 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "693f62de9d1147b78449ec834f4414b0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/720 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e12397bbea83409590801a6b03230175",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/720 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4614ffdb4b3649e38a5851f500f278d8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/720 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0aacdc97e994411aa7d0118e6242fd38",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/720 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------Averaged Perceptron (10 perceptrons)------------------------------\n",
      "\n",
      "Averaged weight vector shape: [-624.37196884  -43.9         338.80006523  445.42600098   53.01106682\n",
      "  151.01993879 -244.9        -330.82000585]\n",
      "Averaged bias value: -59.4000\n",
      "\n",
      "The number of correct preds was 584 for acc of 64.88888888888889%\n",
      "The number of pos preds was 805 and neg num was 95\n",
      "\n",
      "======================================================================\n",
      "Detailed Evaluation Metrics:\n",
      "======================================================================\n",
      "Accuracy: 64.89%\n",
      "Precision: 0.6484\n",
      "Recall: 0.9405\n",
      "F1-Score: 0.7676\n",
      "\n",
      "Confusion Matrix:\n",
      "                Predicted\n",
      "              Fail    Pass\n",
      "Actual Fail     62    283\n",
      "       Pass     33    522\n",
      "\n",
      "Predictions breakdown:\n",
      "  Predicted Fail (0): 95\n",
      "  Predicted Pass (1): 805\n",
      "  Actual Fail (0): 345\n",
      "  Actual Pass (1): 555\n"
     ]
    }
   ],
   "source": [
    "# Averaged Perceptron: Train 10 perceptrons and average their weights\n",
    "n_perceptrons = 10\n",
    "weight_vecs = []\n",
    "bias_vecs = []\n",
    "features_lst = ['Attendance (%)', 'Extracurricular_Activities', 'Midterm_Score', \\\n",
    "       'Assignments_Avg', 'Quizzes_Avg', \\\n",
    "       'Participation_Score', \\\n",
    "       'Stress_Level (1-10)', \\\n",
    "       'Sleep_Hours_per_Night']\n",
    "num_feat = len(features_lst)\n",
    "\n",
    "for i in range(n_perceptrons):\n",
    "    train_ds = MyDataset(train_df, features_lst, 'Grade')\n",
    "    train_dl = DataLoader(train_ds, batch_size=batch_size, shuffle=shuffle)\n",
    "    \n",
    "    w_curr, b_curr, error_curr, weight_hist_curr, tot_train_pos_curr = train_perceptron(train_dl, num_feat, pos_class=1)\n",
    "    \n",
    "    weight_vecs.append(w_curr)\n",
    "    bias_vecs.append(b_curr)\n",
    "\n",
    "# Average the weights and biases\n",
    "w_avg = np.mean(weight_vecs, axis=0)\n",
    "b_avg = np.mean(bias_vecs, axis=0)\n",
    "\n",
    "print(f\"-------------------Averaged Perceptron (10 perceptrons)------------------------------\\n\")\n",
    "print(f\"Averaged weight vector shape: {w_avg}\")\n",
    "print(f\"Averaged bias value: {b_avg:.4f}\\n\")\n",
    "\n",
    "# Test on dev.\n",
    "X_dev_a = dev_df[features_lst].to_numpy()\n",
    "dev_y_true = dev_df['Grade'].to_numpy()\n",
    "dev_y_pred = ((X_dev_a @ w_avg + b_avg) > 0).astype(int)\n",
    "n_correct_dev = (dev_y_true==dev_y_pred).sum(axis=0)\n",
    "\n",
    "print(f\"The number of correct preds was {n_correct_dev} for acc of {(n_correct_dev/dev_y_true.shape[0])*100}%\")\n",
    "print(f\"The number of pos preds was {(dev_y_pred==1).sum(axis=0)} and neg num was {(dev_y_pred==0).sum(axis=0)}\")\n",
    "\n",
    "# Additional detailed metrics\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix\n",
    "\n",
    "accuracy = accuracy_score(dev_y_true, dev_y_pred)\n",
    "precision = precision_score(dev_y_true, dev_y_pred, zero_division=0)\n",
    "recall = recall_score(dev_y_true, dev_y_pred, zero_division=0)\n",
    "f1 = f1_score(dev_y_true, dev_y_pred, zero_division=0)\n",
    "cm = confusion_matrix(dev_y_true, dev_y_pred)\n",
    "\n",
    "print(f\"\\n{'='*70}\")\n",
    "print(\"Detailed Evaluation Metrics:\")\n",
    "print(f\"{'='*70}\")\n",
    "print(f\"Accuracy: {accuracy*100:.2f}%\")\n",
    "print(f\"Precision: {precision:.4f}\")\n",
    "print(f\"Recall: {recall:.4f}\")\n",
    "print(f\"F1-Score: {f1:.4f}\")\n",
    "\n",
    "print(f\"\\nConfusion Matrix:\")\n",
    "print(f\"                Predicted\")\n",
    "print(f\"              Fail    Pass\")\n",
    "print(f\"Actual Fail   {cm[0,0]:4d}   {cm[0,1]:4d}\")\n",
    "print(f\"       Pass   {cm[1,0]:4d}   {cm[1,1]:4d}\")\n",
    "\n",
    "print(f\"\\nPredictions breakdown:\")\n",
    "print(f\"  Predicted Fail (0): {(dev_y_pred==0).sum()}\")\n",
    "print(f\"  Predicted Pass (1): {(dev_y_pred==1).sum()}\")\n",
    "print(f\"  Actual Fail (0): {(dev_y_true==0).sum()}\")\n",
    "print(f\"  Actual Pass (1): {(dev_y_true==1).sum()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80d8a928-6a3c-4c0c-bc9a-523a88141e52",
   "metadata": {},
   "source": [
    "# After Final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "12eafc0b-00f4-422e-9f14-1a60c78849d6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8e12d66849204284b96d49f3c0b55d34",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/720 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f38c5cf981aa4bf1a8fd973bcdd0e1de",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/720 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cf14fc90a2624fe7b84898a52d627d31",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/720 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "247ebc4d883a40f9bd9cf524b0c94a66",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/720 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "70f10156e93047ec82bb22e918af3e1e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/720 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4d09545ff6484481ab2cbab18a1804b7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/720 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5d1ecc4f9dd14e8b88cfc841594964b9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/720 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1d602a3ee82e42c5ad1a6eba2eb9623e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/720 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1b86e7d7ba054795bbcab676e93240a6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/720 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "70f1c46da78d457d8cb43f06a12e5fd4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/720 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------Averaged Perceptron (10 perceptrons)------------------------------\n",
      "\n",
      "Averaged weight vector shape: [-1346.63296585   -60.1          200.47207565  1118.04100075\n",
      "  -166.48002281  -569.77291794   229.19995375  1016.20099869\n",
      "  -344.4         -551.98000903]\n",
      "Averaged bias value: -94.5000\n",
      "\n",
      "The number of correct preds was 633 for acc of 70.33333333333334%\n",
      "The number of pos preds was 630 and neg num was 270\n",
      "\n",
      "======================================================================\n",
      "Detailed Evaluation Metrics:\n",
      "======================================================================\n",
      "Accuracy: 70.33%\n",
      "Precision: 0.7286\n",
      "Recall: 0.8270\n",
      "F1-Score: 0.7747\n",
      "\n",
      "Confusion Matrix:\n",
      "                Predicted\n",
      "              Fail    Pass\n",
      "Actual Fail    174    171\n",
      "       Pass     96    459\n",
      "\n",
      "Predictions breakdown:\n",
      "  Predicted Fail (0): 270\n",
      "  Predicted Pass (1): 630\n",
      "  Actual Fail (0): 345\n",
      "  Actual Pass (1): 555\n"
     ]
    }
   ],
   "source": [
    "# Averaged Perceptron: Train 10 perceptrons and average their weights\n",
    "n_perceptrons = 10\n",
    "weight_vecs = []\n",
    "bias_vecs = []\n",
    "features_lst = ['Attendance (%)', 'Extracurricular_Activities', 'Midterm_Score', \\\n",
    "       'Final_Score', 'Assignments_Avg', 'Quizzes_Avg', \\\n",
    "       'Participation_Score', 'Projects_Score', \\\n",
    "       'Stress_Level (1-10)', \\\n",
    "       'Sleep_Hours_per_Night']\n",
    "num_feat = len(features_lst)\n",
    "\n",
    "for i in range(n_perceptrons):\n",
    "    train_ds = MyDataset(train_df, features_lst, 'Grade')\n",
    "    train_dl = DataLoader(train_ds, batch_size=batch_size, shuffle=shuffle)\n",
    "    \n",
    "    w_curr, b_curr, error_curr, weight_hist_curr, tot_train_pos_curr = train_perceptron(train_dl, num_feat, pos_class=1)\n",
    "    \n",
    "    weight_vecs.append(w_curr)\n",
    "    bias_vecs.append(b_curr)\n",
    "\n",
    "# Average the weights and biases\n",
    "w_avg = np.mean(weight_vecs, axis=0)\n",
    "b_avg = np.mean(bias_vecs, axis=0)\n",
    "\n",
    "print(f\"-------------------Averaged Perceptron (10 perceptrons)------------------------------\\n\")\n",
    "print(f\"Averaged weight vector shape: {w_avg}\")\n",
    "print(f\"Averaged bias value: {b_avg:.4f}\\n\")\n",
    "\n",
    "# Test on dev.\n",
    "X_dev_a = dev_df[features_lst].to_numpy()\n",
    "dev_y_true = dev_df['Grade'].to_numpy()\n",
    "dev_y_pred = ((X_dev_a @ w_avg + b_avg) > 0).astype(int)\n",
    "n_correct_dev = (dev_y_true==dev_y_pred).sum(axis=0)\n",
    "\n",
    "print(f\"The number of correct preds was {n_correct_dev} for acc of {(n_correct_dev/dev_y_true.shape[0])*100}%\")\n",
    "print(f\"The number of pos preds was {(dev_y_pred==1).sum(axis=0)} and neg num was {(dev_y_pred==0).sum(axis=0)}\")\n",
    "\n",
    "# Additional detailed metrics\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix\n",
    "\n",
    "accuracy = accuracy_score(dev_y_true, dev_y_pred)\n",
    "precision = precision_score(dev_y_true, dev_y_pred, zero_division=0)\n",
    "recall = recall_score(dev_y_true, dev_y_pred, zero_division=0)\n",
    "f1 = f1_score(dev_y_true, dev_y_pred, zero_division=0)\n",
    "cm = confusion_matrix(dev_y_true, dev_y_pred)\n",
    "\n",
    "print(f\"\\n{'='*70}\")\n",
    "print(\"Detailed Evaluation Metrics:\")\n",
    "print(f\"{'='*70}\")\n",
    "print(f\"Accuracy: {accuracy*100:.2f}%\")\n",
    "print(f\"Precision: {precision:.4f}\")\n",
    "print(f\"Recall: {recall:.4f}\")\n",
    "print(f\"F1-Score: {f1:.4f}\")\n",
    "\n",
    "print(f\"\\nConfusion Matrix:\")\n",
    "print(f\"                Predicted\")\n",
    "print(f\"              Fail    Pass\")\n",
    "print(f\"Actual Fail   {cm[0,0]:4d}   {cm[0,1]:4d}\")\n",
    "print(f\"       Pass   {cm[1,0]:4d}   {cm[1,1]:4d}\")\n",
    "\n",
    "print(f\"\\nPredictions breakdown:\")\n",
    "print(f\"  Predicted Fail (0): {(dev_y_pred==0).sum()}\")\n",
    "print(f\"  Predicted Pass (1): {(dev_y_pred==1).sum()}\")\n",
    "print(f\"  Actual Fail (0): {(dev_y_true==0).sum()}\")\n",
    "print(f\"  Actual Pass (1): {(dev_y_true==1).sum()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71f40813-920e-4707-bfed-f2398d86c486",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
