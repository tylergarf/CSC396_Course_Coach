{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a136d87f-81e8-4e65-9d30-75fcd2c6ff7b",
   "metadata": {},
   "source": [
    "# Performing needed imports and boilder plate code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "472cc83c-1425-47ed-b290-9039207e03ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "from tqdm.notebook import tqdm\n",
    "import pandas as pd\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "# set this variable to a number to be used as the random seed\n",
    "# or to None if you don't want to set a random seed\n",
    "seed = 1234\n",
    "\n",
    "if seed is not None:\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c7b032e-e4dc-4cb0-96e2-5b5acaeb463c",
   "metadata": {},
   "source": [
    "# Copied over data cleaning steps from our data cleaning notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5c4c7721-2d24-48e9-bd40-e66aea329f0f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_764926/54308773.py:7: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  education_data['Gender'] = education_data['Gender'].replace({'Male': 1, 'Female': 0}).astype(int)\n",
      "/tmp/ipykernel_764926/54308773.py:8: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  education_data['Internet_Access_at_Home'] = education_data['Internet_Access_at_Home'].replace({'Yes': 1, 'No': 0}).astype(int)\n",
      "/tmp/ipykernel_764926/54308773.py:9: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  education_data['Extracurricular_Activities'] = education_data['Extracurricular_Activities'].replace({'Yes': 1, 'No': 0}).astype(int)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Gender</th>\n",
       "      <th>Age</th>\n",
       "      <th>Department</th>\n",
       "      <th>department index</th>\n",
       "      <th>Attendance (%)</th>\n",
       "      <th>Midterm_Score</th>\n",
       "      <th>Final_Score</th>\n",
       "      <th>Assignments_Avg</th>\n",
       "      <th>Quizzes_Avg</th>\n",
       "      <th>Participation_Score</th>\n",
       "      <th>Projects_Score</th>\n",
       "      <th>Total_Score</th>\n",
       "      <th>Grade</th>\n",
       "      <th>Study_Hours_per_Week</th>\n",
       "      <th>Extracurricular_Activities</th>\n",
       "      <th>Internet_Access_at_Home</th>\n",
       "      <th>Family_Income_Level</th>\n",
       "      <th>Stress_Level (1-10)</th>\n",
       "      <th>Sleep_Hours_per_Night</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>22</td>\n",
       "      <td>Mathematics</td>\n",
       "      <td>0</td>\n",
       "      <td>97.36</td>\n",
       "      <td>40.61</td>\n",
       "      <td>59.61</td>\n",
       "      <td>73.69</td>\n",
       "      <td>53.17</td>\n",
       "      <td>73.4</td>\n",
       "      <td>62.84</td>\n",
       "      <td>59.8865</td>\n",
       "      <td>4</td>\n",
       "      <td>10.3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>5.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>18</td>\n",
       "      <td>Business</td>\n",
       "      <td>1</td>\n",
       "      <td>97.71</td>\n",
       "      <td>57.27</td>\n",
       "      <td>74.00</td>\n",
       "      <td>74.23</td>\n",
       "      <td>98.23</td>\n",
       "      <td>88.0</td>\n",
       "      <td>98.23</td>\n",
       "      <td>81.9170</td>\n",
       "      <td>1</td>\n",
       "      <td>27.1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>4.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>24</td>\n",
       "      <td>Engineering</td>\n",
       "      <td>2</td>\n",
       "      <td>99.52</td>\n",
       "      <td>41.84</td>\n",
       "      <td>63.85</td>\n",
       "      <td>85.85</td>\n",
       "      <td>50.00</td>\n",
       "      <td>4.7</td>\n",
       "      <td>91.22</td>\n",
       "      <td>67.7170</td>\n",
       "      <td>3</td>\n",
       "      <td>12.4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>6.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>24</td>\n",
       "      <td>Engineering</td>\n",
       "      <td>2</td>\n",
       "      <td>90.38</td>\n",
       "      <td>45.65</td>\n",
       "      <td>44.44</td>\n",
       "      <td>68.10</td>\n",
       "      <td>66.27</td>\n",
       "      <td>4.2</td>\n",
       "      <td>55.48</td>\n",
       "      <td>51.6535</td>\n",
       "      <td>4</td>\n",
       "      <td>25.5</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>4.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>23</td>\n",
       "      <td>CS</td>\n",
       "      <td>3</td>\n",
       "      <td>59.41</td>\n",
       "      <td>53.13</td>\n",
       "      <td>61.77</td>\n",
       "      <td>67.66</td>\n",
       "      <td>83.98</td>\n",
       "      <td>64.3</td>\n",
       "      <td>87.43</td>\n",
       "      <td>71.4030</td>\n",
       "      <td>2</td>\n",
       "      <td>13.3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>4.5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Gender  Age   Department  department index  Attendance (%)  Midterm_Score  \\\n",
       "0       0   22  Mathematics                 0           97.36          40.61   \n",
       "1       1   18     Business                 1           97.71          57.27   \n",
       "2       1   24  Engineering                 2           99.52          41.84   \n",
       "3       0   24  Engineering                 2           90.38          45.65   \n",
       "4       0   23           CS                 3           59.41          53.13   \n",
       "\n",
       "   Final_Score  Assignments_Avg  Quizzes_Avg  Participation_Score  \\\n",
       "0        59.61            73.69        53.17                 73.4   \n",
       "1        74.00            74.23        98.23                 88.0   \n",
       "2        63.85            85.85        50.00                  4.7   \n",
       "3        44.44            68.10        66.27                  4.2   \n",
       "4        61.77            67.66        83.98                 64.3   \n",
       "\n",
       "   Projects_Score  Total_Score  Grade  Study_Hours_per_Week  \\\n",
       "0           62.84      59.8865      4                  10.3   \n",
       "1           98.23      81.9170      1                  27.1   \n",
       "2           91.22      67.7170      3                  12.4   \n",
       "3           55.48      51.6535      4                  25.5   \n",
       "4           87.43      71.4030      2                  13.3   \n",
       "\n",
       "   Extracurricular_Activities  Internet_Access_at_Home  Family_Income_Level  \\\n",
       "0                           1                        0                    2   \n",
       "1                           0                        0                    1   \n",
       "2                           1                        0                    1   \n",
       "3                           0                        1                    1   \n",
       "4                           1                        0                    2   \n",
       "\n",
       "   Stress_Level (1-10)  Sleep_Hours_per_Night  \n",
       "0                    1                    5.9  \n",
       "1                    4                    4.3  \n",
       "2                    9                    6.1  \n",
       "3                    8                    4.9  \n",
       "4                    6                    4.5  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "education_data = pd.read_csv('students_clean.csv')\n",
    "\n",
    "\n",
    "education_data.drop('Parent_Education_Level', axis=1, inplace=True) \n",
    "\n",
    "\n",
    "education_data['Gender'] = education_data['Gender'].replace({'Male': 1, 'Female': 0}).astype(int)\n",
    "education_data['Internet_Access_at_Home'] = education_data['Internet_Access_at_Home'].replace({'Yes': 1, 'No': 0}).astype(int)\n",
    "education_data['Extracurricular_Activities'] = education_data['Extracurricular_Activities'].replace({'Yes': 1, 'No': 0}).astype(int)\n",
    "\n",
    "\n",
    "# Low = 1, Medium = 2, High = 3\n",
    "mapper = {'low': 1, 'medium': 2, 'high': 3}\n",
    "\n",
    "education_data['Family_Income_Level'] = (\n",
    "    education_data['Family_Income_Level']\n",
    "      .astype(str)                  # works even if the value is already 1/2/3 or NaN\n",
    "      .str.strip().str.lower()\n",
    "      .map(mapper)                  # returns NaN where no mapping found\n",
    "      .fillna(education_data['Family_Income_Level'])  # keepin the original numeric/blank entries\n",
    "      .astype('Int64')              #  nullable integer dtype\n",
    ")\n",
    "\n",
    "labels = open('departments.txt').read().splitlines()\n",
    "department_mapping = {name: index for index, name in enumerate(labels)}\n",
    "department_indices = education_data['Department'].map(department_mapping)\n",
    "education_data.insert(3, 'department index', department_indices)\n",
    "\n",
    "mapper = {'A': 0, 'B': 1, 'C': 2, 'D':3,'F':4}\n",
    "\n",
    "education_data['Grade'] = (\n",
    "    education_data['Grade']\n",
    "      .astype(str)              # convert everything to string\n",
    "      .str.strip().str.upper()  # remove spaces and standardize to uppercase\n",
    "      .map(mapper)              # map letters to numbers\n",
    ")\n",
    "\n",
    "education_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd384bde-8776-4715-be27-1e4987b0464a",
   "metadata": {},
   "source": [
    "# Now defining our data loader and perceptron"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d7ae6abf-6783-4b0e-a3e9-7b40b2700d14",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset\n",
    "import torch\n",
    "\n",
    "class MyDataset(Dataset):\n",
    "    def __init__(self, df, feature_cols, target_col):\n",
    "        self.df = df\n",
    "        self.feature_cols = feature_cols\n",
    "        self.target_col = target_col\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        row = self.df.iloc[index]\n",
    "        x = torch.tensor(row[self.feature_cols].to_numpy(dtype=np.float32), dtype=torch.float32)\n",
    "        y = torch.tensor(row[self.target_col], dtype=torch.long)  # long for classification\n",
    "        return x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cc1ef39c-1a24-43fe-bf3e-9be7e7697d60",
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform_data_for_perc(dataset_df, target_col, features_lst, pos_class):\n",
    "    \n",
    "    # Copy over the data frame.\n",
    "    dataset_df = dataset_df.copy(deep=True)\n",
    "    \n",
    "    # Builld the list of features to select.\n",
    "    features_lst = features_lst.copy()\n",
    "    features_lst.append(target_col)\n",
    "\n",
    "    \n",
    "    # Now actually select the columns in the desired order.\n",
    "    dataset_df = dataset_df[features_lst]\n",
    "    \n",
    "\n",
    "    # Now what we are going to do is apply a function on the target col s.t all instances\n",
    "    # where the target is the given class number are set to 1 and all others to 0.\n",
    "    dataset_df[target_col] = dataset_df[target_col].apply(lambda x: 1 if x==pos_class else 0)\n",
    "\n",
    "\n",
    "    return dataset_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7220d113-16ca-4e46-b771-b8fd567195e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_perceptron(train_dl, n_features, pos_class):\n",
    "    # First initialize the model.\n",
    "    w = np.zeros(n_features)\n",
    "    b = 0\n",
    "    n_errors = 0\n",
    "\n",
    "    # Now loop through each batch.\n",
    "    for batch_idx, (x, y) in tqdm(enumerate(train_dl), total=len(train_dl)):\n",
    "        #print(x)\n",
    "        x_curr_np = x.numpy()\n",
    "        y_curr_np = y.numpy()\n",
    "\n",
    "        # Now perform the training/classification loop.\n",
    "        scores = x_curr_np @ w + b\n",
    "        #print(type(score))\n",
    "\n",
    "        y_pred = (scores > 0).astype(int)\n",
    "\n",
    "        # My hopethisis is for the A class barley any positives are being predicted.\n",
    "        #if y_pred.sum(axis=0) > 0:\n",
    "            #print(f\"For current batch predicted {y_pred.sum(axis=0)} positives\")\n",
    "\n",
    "        # Now we vectorize the update to make this more efficient.\n",
    "        pred_error = y_curr_np - y_pred\n",
    "        n_errors += np.sum(pred_error != 0) # If the pred error is zero then it is correct.\n",
    "\n",
    "        w += (pred_error[:,None]*x_curr_np).sum(axis=0) # Re-shape pred errors to update and only add\n",
    "                                                        # inccorect preds, axis=0 for rows.\n",
    "        b += pred_error.sum()\n",
    "        \n",
    "\n",
    "    # Now once we are done training the result is the weights and biases.\n",
    "    return (w,b,n_errors)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "705c0939-c452-47a5-a973-7007d82813a2",
   "metadata": {},
   "source": [
    "# Create the training and testing partitions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d92df580-200c-4b7d-943e-21adc213eb6d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train rows: 3,200\n",
      "dev rows: 800\n",
      "test rows: 1,000\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "train_df, test_df = train_test_split(education_data, train_size=0.8)\n",
    "train_df,dev_df = train_test_split(train_df, train_size=0.8)\n",
    "\n",
    "train_df.reset_index(inplace=True,drop=True)\n",
    "dev_df.reset_index(inplace=True,drop=True)\n",
    "test_df.reset_index(inplace=True,drop=True)\n",
    "\n",
    "\n",
    "print(f'train rows: {len(train_df.index):,}')\n",
    "print(f'dev rows: {len(dev_df.index):,}')\n",
    "print(f'test rows: {len(test_df.index):,}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a9940c6-6dc7-4917-be9d-ac08f8c50b4c",
   "metadata": {},
   "source": [
    "# Now actually perform the training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "244bf77c-e8cd-4f7e-a14b-59663afc28f5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8be6323858604668be3f02e3e448934e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/640 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------Report for class 0------------------------------\n",
      "\n",
      "The current class 0 had 26 pred errors in training, the weight vector:\n",
      "\n",
      "[ -14.           -4.          -77.         -318.439991      6.41999054\n",
      "   85.          -79.04001999 -183.89999771   30.1999836   -93.43998718\n",
      "  -34.55500031  -81.60000086   -5.          -29.          -19.19999838]\n",
      "With bias value -4\n",
      "The number of correct preds was 796 for acc of 99.5%\n",
      "The number of pos preds was 0 and neg num was 800\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3e95e912bbf5422bae1225845738f074",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/640 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------Report for class 1------------------------------\n",
      "\n",
      "The current class 1 had 26 pred errors in training, the weight vector:\n",
      "\n",
      "[  -2.           -2.          -57.         -136.439991    -11.19001007\n",
      " -115.56999207 -131.81001282 -192.56997681  181.60000229 -104.88999939\n",
      "  -91.98649597  -32.70000219   -2.          -15.          -16.19999886]\n",
      "With bias value -4\n",
      "The number of correct preds was 705 for acc of 88.125%\n",
      "The number of pos preds was 0 and neg num was 800\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a835536e4c3746c09c365cb1160463c3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/640 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------Report for class 2------------------------------\n",
      "\n",
      "The current class 2 had 0 pred errors in training, the weight vector:\n",
      "\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "With bias value 0\n",
      "The number of correct preds was 437 for acc of 54.625%\n",
      "The number of pos preds was 0 and neg num was 800\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "61c122002cad4f79bbed3d645d79a0a4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/640 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------Report for class 3------------------------------\n",
      "\n",
      "The current class 3 had 0 pred errors in training, the weight vector:\n",
      "\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "With bias value 0\n",
      "The number of correct preds was 502 for acc of 62.74999999999999%\n",
      "The number of pos preds was 0 and neg num was 800\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "851f007b839146f5b5c94be505fdbc2d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/640 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------Report for class 4------------------------------\n",
      "\n",
      "The current class 4 had 0 pred errors in training, the weight vector:\n",
      "\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "With bias value 0\n",
      "The number of correct preds was 760 for acc of 95.0%\n",
      "The number of pos preds was 0 and neg num was 800\n"
     ]
    }
   ],
   "source": [
    "batch_size = 5\n",
    "shuffle = True\n",
    "\n",
    "features_lst = ['department index','Gender', 'Age', 'Attendance (%)', \\\n",
    "       'Midterm_Score', 'Final_Score', 'Assignments_Avg', 'Quizzes_Avg', \\\n",
    "       'Participation_Score', 'Projects_Score', 'Total_Score', \\\n",
    "       'Study_Hours_per_Week', \\\n",
    "       'Family_Income_Level', 'Stress_Level (1-10)', \\\n",
    "       'Sleep_Hours_per_Night']\n",
    "num_feat = len(features_lst)\n",
    "\n",
    "\n",
    "# first create a list of the weight vectors and biases for all the classes.\n",
    "weight_vecs = []\n",
    "bias_vecs = []\n",
    "\n",
    "# The class indexes for all the different grade classes.\n",
    "class_nums = [0,1,2,3,4]\n",
    "\n",
    "# Now loop through each class and record it's performance on the test set.\n",
    "for class_n in class_nums:\n",
    "    # First use the above class to create a data loader with the appropriete current positive class labels.\n",
    "    train_df = transform_data_for_perc(train_df,'Grade',features_lst,class_n)\n",
    "    train_ds = MyDataset( train_df,features_lst,'Grade')\n",
    "    train_dl = DataLoader(train_ds,batch_size=batch_size,shuffle=shuffle)\n",
    "\n",
    "    # Now run it through the perceptron to get the weight vector and bias for the current class.\n",
    "    w_curr,b_curr,error_curr = train_perceptron(train_dl,num_feat,class_n)\n",
    "\n",
    "    # Append current weights to overall weights.\n",
    "    weight_vecs.append(w_curr)\n",
    "    bias_vecs.append(b_curr)\n",
    "\n",
    "    print(f\"-------------------Report for class {class_n}------------------------------\\n\")\n",
    "    print(f\"The current class {class_n} had {error_curr} pred errors in training, the weight vector:\\n\")\n",
    "    print(w_curr)\n",
    "    print(f\"With bias value {b_curr}\")\n",
    "\n",
    "    # Test on dev.\n",
    "    dev_df_a = transform_data_for_perc(dev_df,'Grade',features_lst,class_n)\n",
    "    X_dev_a = dev_df_a[features_lst]\n",
    "\n",
    "    dev_y_true = dev_df_a['Grade'].to_numpy()\n",
    "    dev_y_pred = ((X_dev_a @ w_curr + b_curr) > 0).astype(int)\n",
    "    n_correct_dev = (dev_y_true==dev_y_pred).sum(axis=0)\n",
    "\n",
    "    print(f\"The number of correct preds was {n_correct_dev} for acc of {(n_correct_dev/dev_y_true.shape[0])*100}%\")\n",
    "    print(f\"The number of pos preds was {(dev_y_pred==1).sum(axis=0)} and neg num was {(dev_y_pred==0).sum(axis=0)}\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "421cbdde-2b88-4eb7-b24a-a8a99dedda19",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
