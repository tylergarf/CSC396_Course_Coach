{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "header-cell",
   "metadata": {},
   "source": [
    "# Extracting Misclassified Examples from Averaged Perceptron\n",
    "\n",
    "trid to get:\n",
    "15 examples where the model predicted **PASS** but actual was **FAIL** (False Positives)\n",
    "10 example where the model predicted **FAIL** but actual was **PASS** (False Negatives)\n",
    "\n",
    "Used davids avf pperceptron "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "imports-header",
   "metadata": {},
   "source": [
    "## 1. Imports and Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "imports-cell",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done runnin\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "import torch\n",
    "import numpy as np\n",
    "from tqdm.notebook import tqdm\n",
    "import pandas as pd\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Set random seed for reproducibility\n",
    "seed = 1234\n",
    "\n",
    "if seed is not None:\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.manual_seed(seed)\n",
    "        torch.cuda.manual_seed_all(seed)\n",
    "\n",
    "print(\"done runnin\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "data-cleaning-header",
   "metadata": {},
   "source": [
    "## 2. Data Cleaning (from Data_Cleaning_Code.ipynb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "data-cleaning-cell",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_677210/1122780081.py:6: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  education_data['Gender'] = education_data['Gender'].replace({'Male': 1, 'Female': 0}).astype(int)\n",
      "/tmp/ipykernel_677210/1122780081.py:7: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  education_data['Internet_Access_at_Home'] = education_data['Internet_Access_at_Home'].replace({'Yes': 1, 'No': 0}).astype(int)\n",
      "/tmp/ipykernel_677210/1122780081.py:8: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  education_data['Extracurricular_Activities'] = education_data['Extracurricular_Activities'].replace({'Yes': 1, 'No': 0}).astype(int)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Gender</th>\n",
       "      <th>Age</th>\n",
       "      <th>Department</th>\n",
       "      <th>department index</th>\n",
       "      <th>Attendance (%)</th>\n",
       "      <th>Midterm_Score</th>\n",
       "      <th>Final_Score</th>\n",
       "      <th>Assignments_Avg</th>\n",
       "      <th>Quizzes_Avg</th>\n",
       "      <th>Participation_Score</th>\n",
       "      <th>Projects_Score</th>\n",
       "      <th>Total_Score</th>\n",
       "      <th>Grade</th>\n",
       "      <th>Study_Hours_per_Week</th>\n",
       "      <th>Extracurricular_Activities</th>\n",
       "      <th>Internet_Access_at_Home</th>\n",
       "      <th>Family_Income_Level</th>\n",
       "      <th>Stress_Level (1-10)</th>\n",
       "      <th>Sleep_Hours_per_Night</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>22</td>\n",
       "      <td>Mathematics</td>\n",
       "      <td>0</td>\n",
       "      <td>97.36</td>\n",
       "      <td>40.61</td>\n",
       "      <td>59.61</td>\n",
       "      <td>73.69</td>\n",
       "      <td>53.17</td>\n",
       "      <td>73.4</td>\n",
       "      <td>62.84</td>\n",
       "      <td>59.8865</td>\n",
       "      <td>0</td>\n",
       "      <td>10.3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>5.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>18</td>\n",
       "      <td>Business</td>\n",
       "      <td>1</td>\n",
       "      <td>97.71</td>\n",
       "      <td>57.27</td>\n",
       "      <td>74.00</td>\n",
       "      <td>74.23</td>\n",
       "      <td>98.23</td>\n",
       "      <td>88.0</td>\n",
       "      <td>98.23</td>\n",
       "      <td>81.9170</td>\n",
       "      <td>1</td>\n",
       "      <td>27.1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>4.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>24</td>\n",
       "      <td>Engineering</td>\n",
       "      <td>2</td>\n",
       "      <td>99.52</td>\n",
       "      <td>41.84</td>\n",
       "      <td>63.85</td>\n",
       "      <td>85.85</td>\n",
       "      <td>50.00</td>\n",
       "      <td>4.7</td>\n",
       "      <td>91.22</td>\n",
       "      <td>67.7170</td>\n",
       "      <td>0</td>\n",
       "      <td>12.4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>6.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>24</td>\n",
       "      <td>Engineering</td>\n",
       "      <td>2</td>\n",
       "      <td>90.38</td>\n",
       "      <td>45.65</td>\n",
       "      <td>44.44</td>\n",
       "      <td>68.10</td>\n",
       "      <td>66.27</td>\n",
       "      <td>4.2</td>\n",
       "      <td>55.48</td>\n",
       "      <td>51.6535</td>\n",
       "      <td>0</td>\n",
       "      <td>25.5</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>4.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>23</td>\n",
       "      <td>CS</td>\n",
       "      <td>3</td>\n",
       "      <td>59.41</td>\n",
       "      <td>53.13</td>\n",
       "      <td>61.77</td>\n",
       "      <td>67.66</td>\n",
       "      <td>83.98</td>\n",
       "      <td>64.3</td>\n",
       "      <td>87.43</td>\n",
       "      <td>71.4030</td>\n",
       "      <td>1</td>\n",
       "      <td>13.3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>4.5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Gender  Age   Department  department index  Attendance (%)  Midterm_Score  \\\n",
       "0       0   22  Mathematics                 0           97.36          40.61   \n",
       "1       1   18     Business                 1           97.71          57.27   \n",
       "2       1   24  Engineering                 2           99.52          41.84   \n",
       "3       0   24  Engineering                 2           90.38          45.65   \n",
       "4       0   23           CS                 3           59.41          53.13   \n",
       "\n",
       "   Final_Score  Assignments_Avg  Quizzes_Avg  Participation_Score  \\\n",
       "0        59.61            73.69        53.17                 73.4   \n",
       "1        74.00            74.23        98.23                 88.0   \n",
       "2        63.85            85.85        50.00                  4.7   \n",
       "3        44.44            68.10        66.27                  4.2   \n",
       "4        61.77            67.66        83.98                 64.3   \n",
       "\n",
       "   Projects_Score  Total_Score  Grade  Study_Hours_per_Week  \\\n",
       "0           62.84      59.8865      0                  10.3   \n",
       "1           98.23      81.9170      1                  27.1   \n",
       "2           91.22      67.7170      0                  12.4   \n",
       "3           55.48      51.6535      0                  25.5   \n",
       "4           87.43      71.4030      1                  13.3   \n",
       "\n",
       "   Extracurricular_Activities  Internet_Access_at_Home  Family_Income_Level  \\\n",
       "0                           1                        0                    2   \n",
       "1                           0                        0                    1   \n",
       "2                           1                        0                    1   \n",
       "3                           0                        1                    1   \n",
       "4                           1                        0                    2   \n",
       "\n",
       "   Stress_Level (1-10)  Sleep_Hours_per_Night  \n",
       "0                    1                    5.9  \n",
       "1                    4                    4.3  \n",
       "2                    9                    6.1  \n",
       "3                    8                    4.9  \n",
       "4                    6                    4.5  "
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "education_data = pd.read_csv('students_clean.csv')\n",
    "\n",
    "\n",
    "education_data.drop('Parent_Education_Level', axis=1, inplace=True) \n",
    "\n",
    "education_data['Gender'] = education_data['Gender'].replace({'Male': 1, 'Female': 0}).astype(int)\n",
    "education_data['Internet_Access_at_Home'] = education_data['Internet_Access_at_Home'].replace({'Yes': 1, 'No': 0}).astype(int)\n",
    "education_data['Extracurricular_Activities'] = education_data['Extracurricular_Activities'].replace({'Yes': 1, 'No': 0}).astype(int)\n",
    "\n",
    "\n",
    "# Low = 1, Medium = 2, High = 3\n",
    "mapper = {'low': 1, 'medium': 2, 'high': 3}\n",
    "\n",
    "education_data['Family_Income_Level'] = (\n",
    "    education_data['Family_Income_Level']\n",
    "      .astype(str)                  # works even if the value is already 1/2/3 or NaN\n",
    "      .str.strip().str.lower()\n",
    "      .map(mapper)                  # returns NaN where no mapping found\n",
    "      .fillna(education_data['Family_Income_Level'])  # keepin the original numeric/blank entries\n",
    "      .astype('Int64')              #  nullable integer dtype\n",
    ")\n",
    "\n",
    "labels = open('departments.txt').read().splitlines()\n",
    "department_mapping = {name: index for index, name in enumerate(labels)}\n",
    "department_indices = education_data['Department'].map(department_mapping)\n",
    "education_data.insert(3, 'department index', department_indices)\n",
    "\n",
    "mapper = {'A': 1, 'B': 1, 'C': 1, 'D':0,'F':0}\n",
    "\n",
    "education_data['Grade'] = (\n",
    "    education_data['Grade']\n",
    "      .astype(str)              # convert everything to string\n",
    "      .str.strip().str.upper()  # remove spaces and standardize to uppercase\n",
    "      .map(mapper)              # map letters to numbers\n",
    ")\n",
    "\n",
    "education_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dataset-header",
   "metadata": {},
   "source": [
    "## 3. Dataset Class and Perceptron (from our codebase)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "dataset-class-cell",
   "metadata": {},
   "outputs": [],
   "source": [
    "#  class from perceptron notebook\n",
    "class MyDataset(Dataset):\n",
    "    def __init__(self, df, feature_cols, target_col):\n",
    "        self.df = df\n",
    "        self.feature_cols = feature_cols\n",
    "        self.target_col = target_col\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        row = self.df.iloc[index]\n",
    "        x = torch.tensor(row[self.feature_cols].to_numpy(dtype=np.float32), dtype=torch.float32)\n",
    "        y = torch.tensor(row[self.target_col], dtype=torch.long)\n",
    "        return x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "perceptron-cell",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_perceptron(train_dl, n_features, pos_class):\n",
    "    # First initialize the model.\n",
    "    w = np.zeros(n_features)\n",
    "    b = 0\n",
    "    n_errors = 0\n",
    "    weight_steps = []\n",
    "    total_pos_in_train = 0\n",
    "\n",
    "    # Adding this in for debug purposes to track the changes to the weight vectors on each\n",
    "    # round.\n",
    "    \n",
    "    # Average perceptron features\n",
    "    totalW = np.zeros(n_features)\n",
    "    totalB = 0;\n",
    "    updateCount = 0;\n",
    "    \n",
    "    # Now loop through each batch.\n",
    "    for batch_idx, (x, y) in tqdm(enumerate(train_dl), total=len(train_dl),):\n",
    "        \n",
    "        x_curr_np = x.numpy()\n",
    "        y_curr_np = y.numpy()\n",
    "\n",
    "        total_pos_in_train += (y_curr_np == 1).sum(axis=0)\n",
    "        \n",
    "\n",
    "        # Now perform the training/classification loop.\n",
    "        scores = x_curr_np @ w + b\n",
    "       \n",
    "        \n",
    "        y_pred = (scores > 0).astype(int)\n",
    "\n",
    "\n",
    "        # Now we vectorize the update to make this more efficient.\n",
    "        pred_error = y_curr_np - y_pred\n",
    "        n_errors += np.sum(np.abs(pred_error) != 0) # If the pred error is zero then it is correct.\n",
    "\n",
    "        # First append the previous weights to weight steps which will be used for debuging puprposes.\n",
    "        weight_steps.append((pred_error[:,None]*x_curr_np).sum(axis=0).copy())\n",
    "        \n",
    "        w += (pred_error[:,None]*x_curr_np).sum(axis=0) # Re-shape pred errors to update and only add\n",
    "                                                        # inccorect preds, axis=0 for rows.\n",
    "        b += pred_error.sum()\n",
    "\n",
    "        # Now print out the weights and bias updates every update if we are in debug mode.\n",
    "        \n",
    "\n",
    "    # Now once we are done training the result is the weights and biases.\n",
    "    return (w,b,n_errors,weight_steps.copy(),total_pos_in_train) # I am just copying to avoid weird cases due to mutability of list."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "train-test-split-header",
   "metadata": {},
   "source": [
    "## 4. Create Train/Dev/Test Splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "train-test-split-cell",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train rows: 3,600\n",
      "Dev rows: 900\n",
      "Test rows: 500\n",
      "\n",
      "Dev set Pass/Fail distribution:\n",
      "  Pass (1): 555\n",
      "  Fail (0): 345\n"
     ]
    }
   ],
   "source": [
    "# Split using same random state as our PassFail notebook\n",
    "train_df, test_df = train_test_split(education_data, train_size=0.9, random_state=seed)\n",
    "train_df, dev_df = train_test_split(train_df, train_size=0.8, random_state=seed)\n",
    "\n",
    "train_df.reset_index(inplace=True, drop=True)\n",
    "dev_df.reset_index(inplace=True, drop=True)\n",
    "test_df.reset_index(inplace=True, drop=True)\n",
    "\n",
    "print(f'Train rows: {len(train_df):,}')\n",
    "print(f'Dev rows: {len(dev_df):,}')\n",
    "print(f'Test rows: {len(test_df):,}')\n",
    "\n",
    "print(f\"\\nDev set Pass/Fail distribution:\")\n",
    "print(f\"  Pass (1): {(dev_df['Grade'] == 1).sum()}\")\n",
    "print(f\"  Fail (0): {(dev_df['Grade'] == 0).sum()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "train-avg-perceptron-header",
   "metadata": {},
   "source": [
    "## 5. Train Averaged Perceptron (10 models)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "train-avg-perceptron-cell",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training 10 perceptrons...\n",
      "\n",
      "Training perceptron 1/10\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7dc885bff02e4f8494cd40b8c0443b0a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/57 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training perceptron 2/10\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "14fad6ce79c74122a47a36ba3abec29f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/57 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training perceptron 3/10\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fa11e4b0d7654a978ae480682598a92a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/57 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training perceptron 4/10\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "863af5f6a6cc45509079c42f9f9d67fa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/57 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training perceptron 5/10\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4b5c16c6c0bd449c88b71ed9d23d5cc2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/57 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training perceptron 6/10\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c7118f1dd96f4a0485443c7d650cd470",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/57 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training perceptron 7/10\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "360fc3b892b64c8bb1e6bd18c3744d28",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/57 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training perceptron 8/10\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "83826aec3a1b4ab2a76ba969fa6714bf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/57 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training perceptron 9/10\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7334c9a1ba074fa594797f71985356f5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/57 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training perceptron 10/10\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9b8396934a274ae4a1b878a3fc80e028",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/57 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "Averaged Perceptron Training Complete\n",
      "======================================================================\n",
      "Averaged weight vector shape: (10,)\n",
      "Averaged bias value: -97.3000\n"
     ]
    }
   ],
   "source": [
    "#using After Final features for most comprehensive results)\n",
    "n_perceptrons = 10\n",
    "weight_vecs = []\n",
    "bias_vecs = []\n",
    "\n",
    "\n",
    "features_lst = ['Attendance (%)', 'Extracurricular_Activities', 'Midterm_Score', \n",
    "                'Final_Score', 'Assignments_Avg', 'Quizzes_Avg', \n",
    "                'Participation_Score', 'Projects_Score', \n",
    "                'Stress_Level (1-10)', 'Sleep_Hours_per_Night']\n",
    "num_feat = len(features_lst)\n",
    "batch_size = 64\n",
    "shuffle = True\n",
    "\n",
    "print(f\"Training {n_perceptrons} perceptrons...\\n\")\n",
    "\n",
    "for i in range(n_perceptrons):\n",
    "    print(f\"Training perceptron {i+1}/{n_perceptrons}\")\n",
    "    train_ds = MyDataset(train_df, features_lst, 'Grade')\n",
    "    train_dl = DataLoader(train_ds, batch_size=batch_size, shuffle=shuffle)\n",
    "    \n",
    "    w_curr, b_curr, error_curr, weight_hist_curr, tot_train_pos_curr = train_perceptron(train_dl, num_feat, pos_class=1)\n",
    "    \n",
    "    weight_vecs.append(w_curr)\n",
    "    bias_vecs.append(b_curr)\n",
    "\n",
    "# Average the weights and biases\n",
    "w_avg = np.mean(weight_vecs, axis=0)\n",
    "b_avg = np.mean(bias_vecs, axis=0)\n",
    "\n",
    "print(f\"\\n{'='*70}\")\n",
    "print(\"Averaged Perceptron Training Complete\")\n",
    "print(f\"{'='*70}\")\n",
    "print(f\"Averaged weight vector shape: {w_avg.shape}\")\n",
    "print(f\"Averaged bias value: {b_avg:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "evaluate-header",
   "metadata": {},
   "source": [
    "## 6. Evaluate on Dev Set and Get Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "evaluate-cell",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dev Set Performance:\n",
      "  Accuracy: 69.33%\n",
      "  Correct predictions: 624/900\n",
      "\n",
      "Prediction Distribution:\n",
      "  Predicted Pass (1): 795\n",
      "  Predicted Fail (0): 105\n"
     ]
    }
   ],
   "source": [
    "# Make predictions on dev set\n",
    "X_dev = dev_df[features_lst].to_numpy()\n",
    "dev_y_true = dev_df['Grade'].to_numpy()\n",
    "dev_y_pred = ((X_dev @ w_avg + b_avg) > 0).astype(int)\n",
    "\n",
    "# accuracy\n",
    "n_correct_dev = (dev_y_true == dev_y_pred).sum()\n",
    "accuracy = (n_correct_dev / dev_y_true.shape[0]) * 100\n",
    "\n",
    "print(f\"Dev Set Performance:\")\n",
    "print(f\"  Accuracy: {accuracy:.2f}%\")\n",
    "print(f\"  Correct predictions: {n_correct_dev}/{len(dev_y_true)}\")\n",
    "print(f\"\\nPrediction Distribution:\")\n",
    "print(f\"  Predicted Pass (1): {(dev_y_pred == 1).sum()}\")\n",
    "print(f\"  Predicted Fail (0): {(dev_y_pred == 0).sum()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "extract-misclassified-header",
   "metadata": {},
   "source": [
    "## 7. Extract Misclassified Examples\n",
    "False Positives (FP): Predicted PASS but actual was FAIL (15 examples)\n",
    "False Negatives (FN): Predicted FAIL but actual was PASS (10 examples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "extract-misclassified-cell",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "Misclassification Summary\n",
      "======================================================================\n",
      "False Positives (predicted Pass, actual Fail): 48\n",
      "False Negatives (predicted Fail, actual Pass): 323\n",
      "\n",
      "Extracting:\n",
      "  - 15 False Positives\n",
      "  - 10 False Negatives\n"
     ]
    }
   ],
   "source": [
    "# extract misclassifications\n",
    "# False Positives: Predicted Pass (1), Actual Fail (0)\n",
    "false_positives_mask = (dev_y_pred == 1) & (dev_y_true == 0)\n",
    "false_positives_indices = np.where(false_positives_mask)[0]\n",
    "\n",
    "# False Negatives: Predicted Fail (0), Actual Pass (1)\n",
    "false_negatives_mask = (dev_y_pred == 0) & (dev_y_true == 1)\n",
    "false_negatives_indices = np.where(false_negatives_mask)[0]\n",
    "\n",
    "print(f\"{'='*70}\")\n",
    "print(\"Misclassification Summary\")\n",
    "print(f\"{'='*70}\")\n",
    "print(f\"False Positives (predicted Pass, actual Fail): {len(false_positives_indices)}\")\n",
    "print(f\"False Negatives (predicted Fail, actual Pass): {len(false_negatives_indices)}\")\n",
    "print(f\"\\nExtracting:\")\n",
    "print(f\"  - 15 False Positives\")\n",
    "print(f\"  - 10 False Negatives\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "fp-examples-cell",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "FALSE POSITIVES: Predicted PASS, Actually FAILED (15 examples)\n",
      "======================================================================\n",
      "\n",
      "     Gender  Age   Department  Attendance (%)  Midterm_Score  Final_Score  Assignments_Avg  Total_Score  Prediction_Score  Predicted_Grade  Actual_Grade\n",
      "8         0   24           CS           70.32          41.14        83.66            66.76      65.4480     311376.803550                1             0\n",
      "19        1   23  Engineering           52.96          78.38        55.22            60.21      67.2125     279356.486499                1             0\n",
      "31        1   19           CS           66.87          72.25        88.65            54.94      69.7470     289219.908868                1             0\n",
      "37        1   20  Engineering           65.60          76.57        75.55            54.99      61.2315     227794.060081                1             0\n",
      "57        1   22  Mathematics           61.57          76.65        58.67            56.18      68.5950     273010.801482                1             0\n",
      "75        0   22  Engineering           63.44          50.81        79.49            50.36      59.7920     250924.226629                1             0\n",
      "84        0   20  Engineering           66.26          48.70        91.29            57.82      69.6975     387554.409452                1             0\n",
      "135       0   23  Engineering           51.90          68.25        50.87            55.48      65.8030     299818.152908                1             0\n",
      "136       1   23  Engineering           50.61          83.63        76.12            67.12      66.8745     408799.812706                1             0\n",
      "140       1   21  Engineering           52.29          61.63        87.64            50.47      66.9520     387296.620129                1             0\n",
      "162       0   19  Engineering           51.15          45.94        74.18            59.72      65.6760     264149.296571                1             0\n",
      "166       1   21  Mathematics           60.60          70.21        64.48            87.85      68.0900     282062.601518                1             0\n",
      "172       1   22  Mathematics           55.70          66.72        41.12            60.90      66.2220     290905.630109                1             0\n",
      "175       0   18  Mathematics           54.78          56.68        57.49            56.47      60.9360     287810.839862                1             0\n",
      "208       0   20           CS           64.86          74.76        83.48            54.28      69.4350     286466.744867                1             0\n",
      "\n",
      "======================================================================\n",
      "False Positive Summary Statistics:\n",
      "======================================================================\n",
      "Average Total Score: 66.11\n",
      "Average Final Score: 71.19\n",
      "Average Attendance: 59.26%\n",
      "Average Prediction Score: 301769.7597\n"
     ]
    }
   ],
   "source": [
    "# xtract 15 False Positives\n",
    "num_fp_to_extract = min(15, len(false_positives_indices))\n",
    "fp_indices = false_positives_indices[:num_fp_to_extract]\n",
    "\n",
    "#  DataFrame with all relevant information\n",
    "false_positives_df = dev_df.iloc[fp_indices].copy()\n",
    "false_positives_df['Predicted_Grade'] = 1  # Pass\n",
    "false_positives_df['Actual_Grade'] = 0     # Fail\n",
    "false_positives_df['Error_Type'] = 'False Positive'\n",
    "\n",
    "# Add prediction scores for analysis\n",
    "false_positives_df['Prediction_Score'] = (X_dev[fp_indices] @ w_avg + b_avg)\n",
    "\n",
    "print(f\"\\n{'='*70}\")\n",
    "print(f\"FALSE POSITIVES: Predicted PASS, Actually FAILED ({num_fp_to_extract} examples)\")\n",
    "print(f\"{'='*70}\\n\")\n",
    "\n",
    "# Display with key features\n",
    "display_cols = ['Gender', 'Age', 'Department', 'Attendance (%)', 'Midterm_Score', \n",
    "                'Final_Score', 'Assignments_Avg', 'Total_Score', \n",
    "                'Prediction_Score', 'Predicted_Grade', 'Actual_Grade']\n",
    "\n",
    "print(false_positives_df[display_cols].to_string(index=True))\n",
    "\n",
    "#  stats\n",
    "print(f\"\\n{'='*70}\")\n",
    "print(\"False Positive Summary Statistics:\")\n",
    "print(f\"{'='*70}\")\n",
    "print(f\"Average Total Score: {false_positives_df['Total_Score'].mean():.2f}\")\n",
    "print(f\"Average Final Score: {false_positives_df['Final_Score'].mean():.2f}\")\n",
    "print(f\"Average Attendance: {false_positives_df['Attendance (%)'].mean():.2f}%\")\n",
    "print(f\"Average Prediction Score: {false_positives_df['Prediction_Score'].mean():.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "fp-detailed-cell",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "FALSE NEGATIVES: Predicted FAIL, Actually PASSED (10 examples)\n",
      "======================================================================\n",
      "\n",
      "    Gender  Age   Department  Attendance (%)  Midterm_Score  Final_Score  Assignments_Avg  Total_Score  Prediction_Score  Predicted_Grade  Actual_Grade\n",
      "0        1   21           CS           92.88          45.43        51.62            94.52      70.5845      42801.751265                0             1\n",
      "2        1   21     Business           98.22          47.15        85.39            97.60      72.3400     163187.006902                0             1\n",
      "3        1   22     Business           80.57          99.83        87.61            90.90      82.2960     169692.011112                0             1\n",
      "4        1   23  Mathematics           81.60          44.80        75.08            91.32      76.7290     249189.706768                0             1\n",
      "5        0   24           CS           84.67          66.00        71.99            95.98      77.2365     176139.783562                0             1\n",
      "6        1   21           CS           89.28          49.40        55.45            99.21      72.6910      23592.634379                0             1\n",
      "7        1   21  Engineering           74.81          96.02        75.85            99.87      76.2540     139905.645494                0             1\n",
      "9        0   19  Engineering           98.37          69.31        83.73            59.24      74.7340      91500.239203                0             1\n",
      "15       1   22  Mathematics           83.19          98.26        46.12            73.90      70.0070      99506.278765                0             1\n",
      "18       1   22  Mathematics           89.21          70.30        77.87            53.95      70.3220     210231.395679                0             1\n",
      "\n",
      "======================================================================\n",
      "False Negative Summary Statistics:\n",
      "======================================================================\n",
      "Average Total Score: 74.32\n",
      "Average Final Score: 71.07\n",
      "Average Attendance: 87.28%\n",
      "Average Prediction Score: 136574.6453\n"
     ]
    }
   ],
   "source": [
    "# Extract 10 False Negatives\n",
    "num_fn_to_extract = min(10, len(false_negatives_indices))\n",
    "fn_indices = false_negatives_indices[:num_fn_to_extract]\n",
    "\n",
    "# Create DataFrame with all relevant information\n",
    "false_negatives_df = dev_df.iloc[fn_indices].copy()\n",
    "false_negatives_df['Predicted_Grade'] = 0  # Fail\n",
    "false_negatives_df['Actual_Grade'] = 1     # Pass\n",
    "false_negatives_df['Error_Type'] = 'False Negative'\n",
    "\n",
    "# Add prediction scores for analysis\n",
    "false_negatives_df['Prediction_Score'] = (X_dev[fn_indices] @ w_avg + b_avg)\n",
    "\n",
    "print(f\"\\n{'='*70}\")\n",
    "print(f\"FALSE NEGATIVES: Predicted FAIL, Actually PASSED ({num_fn_to_extract} examples)\")\n",
    "print(f\"{'='*70}\\n\")\n",
    "\n",
    "# Display with key features\n",
    "print(false_negatives_df[display_cols].to_string(index=True))\n",
    "\n",
    "# Summary statistics\n",
    "print(f\"\\n{'='*70}\")\n",
    "print(\"False Negative Summary Statistics:\")\n",
    "print(f\"{'='*70}\")\n",
    "print(f\"Average Total Score: {false_negatives_df['Total_Score'].mean():.2f}\")\n",
    "print(f\"Average Final Score: {false_negatives_df['Final_Score'].mean():.2f}\")\n",
    "print(f\"Average Attendance: {false_negatives_df['Attendance (%)'].mean():.2f}%\")\n",
    "print(f\"Average Prediction Score: {false_negatives_df['Prediction_Score'].mean():.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "summary-cell",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "SUMMARY\n",
      "================================================================================\n",
      "\n",
      "Averaged Perceptron (trained with 10 models)\n",
      "Features used: 10\n",
      "Dev set accuracy: 6933.33%\n",
      "\n",
      "Misclassification Analysis:\n",
      "  Total False Positives (Predicted PASS, Actual FAIL): 258\n",
      "  Total False Negatives (Predicted FAIL, Actual PASS): 18\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"=\"*80)\n",
    "print(\"SUMMARY\")\n",
    "print(\"=\"*80)\n",
    "print()\n",
    "print(f\"Averaged Perceptron (trained with {n_perceptrons} models)\")\n",
    "print(f\"Features used: {len(features_lst)}\")\n",
    "print(f\"Dev set accuracy: {accuracy*100:.2f}%\")\n",
    "print()\n",
    "print(f\"Misclassification Analysis:\")\n",
    "print(f\"  Total False Positives (Predicted PASS, Actual FAIL): {len(false_positives)}\")\n",
    "print(f\"  Total False Negatives (Predicted FAIL, Actual PASS): {len(false_negatives)}\")\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91b650d9-5634-4de6-a38b-e2543a74e287",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db9451f1-4bdc-49e7-b17a-b88f94b35c4e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "943a914a-b4c9-4a71-ade9-446bc8af6c2e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
