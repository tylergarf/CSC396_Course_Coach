{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a136d87f-81e8-4e65-9d30-75fcd2c6ff7b",
   "metadata": {},
   "source": [
    "# Performing needed imports and boilder plate code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "472cc83c-1425-47ed-b290-9039207e03ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "from tqdm.notebook import tqdm\n",
    "import pandas as pd\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "# set this variable to a number to be used as the random seed\n",
    "# or to None if you don't want to set a random seed\n",
    "seed = 1234\n",
    "\n",
    "if seed is not None:\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.manual_seed(seed)\n",
    "        torch.cuda.manual_seed_all(seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c7b032e-e4dc-4cb0-96e2-5b5acaeb463c",
   "metadata": {},
   "source": [
    "# Copied over data cleaning steps from our data cleaning notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5c4c7721-2d24-48e9-bd40-e66aea329f0f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_726427/2808339658.py:6: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  education_data['Gender'] = education_data['Gender'].replace({'Male': 1, 'Female': 0}).astype(int)\n",
      "/tmp/ipykernel_726427/2808339658.py:7: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  education_data['Internet_Access_at_Home'] = education_data['Internet_Access_at_Home'].replace({'Yes': 1, 'No': 0}).astype(int)\n",
      "/tmp/ipykernel_726427/2808339658.py:8: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  education_data['Extracurricular_Activities'] = education_data['Extracurricular_Activities'].replace({'Yes': 1, 'No': 0}).astype(int)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Gender</th>\n",
       "      <th>Age</th>\n",
       "      <th>department index</th>\n",
       "      <th>Attendance (%)</th>\n",
       "      <th>Midterm_Score</th>\n",
       "      <th>Final_Score</th>\n",
       "      <th>Assignments_Avg</th>\n",
       "      <th>Quizzes_Avg</th>\n",
       "      <th>Participation_Score</th>\n",
       "      <th>Projects_Score</th>\n",
       "      <th>Total_Score</th>\n",
       "      <th>Grade</th>\n",
       "      <th>Study_Hours_per_Week</th>\n",
       "      <th>Extracurricular_Activities</th>\n",
       "      <th>Internet_Access_at_Home</th>\n",
       "      <th>Family_Income_Level</th>\n",
       "      <th>Stress_Level (1-10)</th>\n",
       "      <th>Sleep_Hours_per_Night</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.916667</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.9736</td>\n",
       "      <td>0.406141</td>\n",
       "      <td>0.596219</td>\n",
       "      <td>0.736974</td>\n",
       "      <td>0.531753</td>\n",
       "      <td>0.734</td>\n",
       "      <td>0.6284</td>\n",
       "      <td>0.629778</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.343333</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.655556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.9771</td>\n",
       "      <td>0.572757</td>\n",
       "      <td>0.740148</td>\n",
       "      <td>0.742374</td>\n",
       "      <td>0.982398</td>\n",
       "      <td>0.880</td>\n",
       "      <td>0.9823</td>\n",
       "      <td>0.861454</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.903333</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.477778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.9952</td>\n",
       "      <td>0.418442</td>\n",
       "      <td>0.638628</td>\n",
       "      <td>0.858586</td>\n",
       "      <td>0.500050</td>\n",
       "      <td>0.047</td>\n",
       "      <td>0.9122</td>\n",
       "      <td>0.712125</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.413333</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.677778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.9038</td>\n",
       "      <td>0.456546</td>\n",
       "      <td>0.444489</td>\n",
       "      <td>0.681068</td>\n",
       "      <td>0.662766</td>\n",
       "      <td>0.042</td>\n",
       "      <td>0.5548</td>\n",
       "      <td>0.543198</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.850000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.544444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.958333</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.5941</td>\n",
       "      <td>0.531353</td>\n",
       "      <td>0.617824</td>\n",
       "      <td>0.676668</td>\n",
       "      <td>0.839884</td>\n",
       "      <td>0.643</td>\n",
       "      <td>0.8743</td>\n",
       "      <td>0.750887</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.443333</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Gender       Age  department index  Attendance (%)  Midterm_Score  \\\n",
       "0     0.0  0.916667          0.000000          0.9736       0.406141   \n",
       "1     1.0  0.750000          0.333333          0.9771       0.572757   \n",
       "2     1.0  1.000000          0.666667          0.9952       0.418442   \n",
       "3     0.0  1.000000          0.666667          0.9038       0.456546   \n",
       "4     0.0  0.958333          1.000000          0.5941       0.531353   \n",
       "\n",
       "   Final_Score  Assignments_Avg  Quizzes_Avg  Participation_Score  \\\n",
       "0     0.596219         0.736974     0.531753                0.734   \n",
       "1     0.740148         0.742374     0.982398                0.880   \n",
       "2     0.638628         0.858586     0.500050                0.047   \n",
       "3     0.444489         0.681068     0.662766                0.042   \n",
       "4     0.617824         0.676668     0.839884                0.643   \n",
       "\n",
       "   Projects_Score  Total_Score  Grade  Study_Hours_per_Week  \\\n",
       "0          0.6284     0.629778    0.0              0.343333   \n",
       "1          0.9823     0.861454    1.0              0.903333   \n",
       "2          0.9122     0.712125    0.0              0.413333   \n",
       "3          0.5548     0.543198    0.0              0.850000   \n",
       "4          0.8743     0.750887    1.0              0.443333   \n",
       "\n",
       "   Extracurricular_Activities  Internet_Access_at_Home  Family_Income_Level  \\\n",
       "0                         1.0                      0.0             0.666667   \n",
       "1                         0.0                      0.0             0.333333   \n",
       "2                         1.0                      0.0             0.333333   \n",
       "3                         0.0                      1.0             0.333333   \n",
       "4                         1.0                      0.0             0.666667   \n",
       "\n",
       "   Stress_Level (1-10)  Sleep_Hours_per_Night  \n",
       "0                  0.1               0.655556  \n",
       "1                  0.4               0.477778  \n",
       "2                  0.9               0.677778  \n",
       "3                  0.8               0.544444  \n",
       "4                  0.6               0.500000  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "education_data = pd.read_csv('students_clean.csv')\n",
    "\n",
    "\n",
    "education_data.drop('Parent_Education_Level', axis=1, inplace=True) \n",
    "\n",
    "education_data['Gender'] = education_data['Gender'].replace({'Male': 1, 'Female': 0}).astype(int)\n",
    "education_data['Internet_Access_at_Home'] = education_data['Internet_Access_at_Home'].replace({'Yes': 1, 'No': 0}).astype(int)\n",
    "education_data['Extracurricular_Activities'] = education_data['Extracurricular_Activities'].replace({'Yes': 1, 'No': 0}).astype(int)\n",
    "\n",
    "\n",
    "# Low = 1, Medium = 2, High = 3\n",
    "mapper = {'low': 1, 'medium': 2, 'high': 3}\n",
    "\n",
    "education_data['Family_Income_Level'] = (\n",
    "    education_data['Family_Income_Level']\n",
    "      .astype(str)                  # works even if the value is already 1/2/3 or NaN\n",
    "      .str.strip().str.lower()\n",
    "      .map(mapper)                  # returns NaN where no mapping found\n",
    "      .fillna(education_data['Family_Income_Level'])  # keepin the original numeric/blank entries\n",
    "      .astype('Int64')              #  nullable integer dtype\n",
    ")\n",
    "\n",
    "labels = open('departments.txt').read().splitlines()\n",
    "department_mapping = {name: index for index, name in enumerate(labels)}\n",
    "department_indices = education_data['Department'].map(department_mapping)\n",
    "education_data.insert(3, 'department index', department_indices)\n",
    "\n",
    "mapper = {'A': 1, 'B': 1, 'C': 1, 'D':0,'F':0}\n",
    "\n",
    "education_data['Grade'] = (\n",
    "    education_data['Grade']\n",
    "      .astype(str)              # convert everything to string\n",
    "      .str.strip().str.upper()  # remove spaces and standardize to uppercase\n",
    "      .map(mapper)              # map letters to numbers\n",
    ")\n",
    "education_data = education_data.drop(columns='Department')\n",
    "\n",
    "education_data = education_data.apply(lambda col: col / col.max() if pd.api.types.is_numeric_dtype(col) else col)\n",
    "education_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd384bde-8776-4715-be27-1e4987b0464a",
   "metadata": {},
   "source": [
    "# Now defining our data loader and perceptron"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d7ae6abf-6783-4b0e-a3e9-7b40b2700d14",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset\n",
    "import torch\n",
    "\n",
    "class MyDataset(Dataset):\n",
    "    def __init__(self, df, feature_cols, target_col):\n",
    "        self.df = df\n",
    "        self.feature_cols = feature_cols\n",
    "        self.target_col = target_col\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        row = self.df.iloc[index]\n",
    "        x = torch.tensor(row[self.feature_cols].to_numpy(dtype=np.float32), dtype=torch.float32)\n",
    "        y = torch.tensor(row[self.target_col], dtype=torch.long)  # long for classification\n",
    "        return x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7220d113-16ca-4e46-b771-b8fd567195e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_perceptron(train_dl, n_features, pos_class):\n",
    "    # First initialize the model.\n",
    "    w = np.zeros(n_features)\n",
    "    b = 0\n",
    "    n_errors = 0\n",
    "    weight_steps = []\n",
    "    total_pos_in_train = 0\n",
    "\n",
    "    # Adding this in for debug purposes to track the changes to the weight vectors on each\n",
    "    # round.\n",
    "    \n",
    "    # Average perceptron features\n",
    "    totalW = np.zeros(n_features)\n",
    "    totalB = 0;\n",
    "    updateCount = 0;\n",
    "    \n",
    "    # Now loop through each batch.\n",
    "    for batch_idx, (x, y) in tqdm(enumerate(train_dl), total=len(train_dl),):\n",
    "        \n",
    "        x_curr_np = x.numpy()\n",
    "        y_curr_np = y.numpy()\n",
    "\n",
    "        total_pos_in_train += (y_curr_np == 1).sum(axis=0)\n",
    "        \n",
    "\n",
    "        # Now perform the training/classification loop.\n",
    "        scores = x_curr_np @ w + b\n",
    "       \n",
    "        \n",
    "        y_pred = (scores > 0).astype(int)\n",
    "\n",
    "\n",
    "        # Now we vectorize the update to make this more efficient.\n",
    "        pred_error = y_curr_np - y_pred\n",
    "        n_errors += np.sum(np.abs(pred_error) != 0) # If the pred error is zero then it is correct.\n",
    "\n",
    "        # First append the previous weights to weight steps which will be used for debuging puprposes.\n",
    "        weight_steps.append((pred_error[:,None]*x_curr_np).sum(axis=0).copy())\n",
    "        \n",
    "        w += (pred_error[:,None]*x_curr_np).sum(axis=0) # Re-shape pred errors to update and only add\n",
    "                                                        # inccorect preds, axis=0 for rows.\n",
    "        b += pred_error.sum()\n",
    "\n",
    "        # Now print out the weights and bias updates every update if we are in debug mode.\n",
    "        \n",
    "\n",
    "    # Now once we are done training the result is the weights and biases.\n",
    "    return (w,b,n_errors,weight_steps.copy(),total_pos_in_train) # I am just copying to avoid weird cases due to mutability of list."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "705c0939-c452-47a5-a973-7007d82813a2",
   "metadata": {},
   "source": [
    "# Create the training and testing partitions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d92df580-200c-4b7d-943e-21adc213eb6d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train rows: 3,600\n",
      "dev rows: 900\n",
      "test rows: 500\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "train_df, test_df = train_test_split(education_data, train_size=0.9,random_state=seed)\n",
    "train_df,dev_df = train_test_split(train_df, train_size=0.8,random_state=seed)\n",
    "\n",
    "train_df.reset_index(inplace=True,drop=True)\n",
    "dev_df.reset_index(inplace=True,drop=True)\n",
    "test_df.reset_index(inplace=True,drop=True)\n",
    "\n",
    "\n",
    "print(f'train rows: {len(train_df.index):,}')\n",
    "print(f'dev rows: {len(dev_df.index):,}')\n",
    "print(f'test rows: {len(test_df.index):,}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "dae62e5f-bc8b-4386-99e1-bbf597d4d830",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "Pass/Fail Distribution in Datasets\n",
      "======================================================================\n",
      "\n",
      "Train Set:\n",
      "  Pass (1): 2105 (58.47%)\n",
      "  Fail (0): 1495 (41.53%)\n",
      "  Total: 3600\n",
      "\n",
      "Dev Set:\n",
      "  Pass (1): 555 (61.67%)\n",
      "  Fail (0): 345 (38.33%)\n",
      "  Total: 900\n",
      "\n",
      "Test Set:\n",
      "  Pass (1): 301 (60.20%)\n",
      "  Fail (0): 199 (39.80%)\n",
      "  Total: 500\n"
     ]
    }
   ],
   "source": [
    "# Check pass/fail distribution in train and dev datasets\n",
    "print(\"=\"*70)\n",
    "print(\"Pass/Fail Distribution in Datasets\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Train set distribution\n",
    "train_pass = (train_df['Grade'] == 1).sum()\n",
    "train_fail = (train_df['Grade'] == 0).sum()\n",
    "train_total = len(train_df)\n",
    "\n",
    "print(f\"\\nTrain Set:\")\n",
    "print(f\"  Pass (1): {train_pass} ({train_pass/train_total*100:.2f}%)\")\n",
    "print(f\"  Fail (0): {train_fail} ({train_fail/train_total*100:.2f}%)\")\n",
    "print(f\"  Total: {train_total}\")\n",
    "\n",
    "# Dev set distribution\n",
    "dev_pass = (dev_df['Grade'] == 1).sum()\n",
    "dev_fail = (dev_df['Grade'] == 0).sum()\n",
    "dev_total = len(dev_df)\n",
    "\n",
    "print(f\"\\nDev Set:\")\n",
    "print(f\"  Pass (1): {dev_pass} ({dev_pass/dev_total*100:.2f}%)\")\n",
    "print(f\"  Fail (0): {dev_fail} ({dev_fail/dev_total*100:.2f}%)\")\n",
    "print(f\"  Total: {dev_total}\")\n",
    "\n",
    "# Test set distribution\n",
    "test_pass = (test_df['Grade'] == 1).sum()\n",
    "test_fail = (test_df['Grade'] == 0).sum()\n",
    "test_total = len(test_df)\n",
    "\n",
    "print(f\"\\nTest Set:\")\n",
    "print(f\"  Pass (1): {test_pass} ({test_pass/test_total*100:.2f}%)\")\n",
    "print(f\"  Fail (0): {test_fail} ({test_fail/test_total*100:.2f}%)\")\n",
    "print(f\"  Total: {test_total}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93cec73b-a7a7-4b6c-ab49-0ddb949b5b3a",
   "metadata": {},
   "source": [
    "# Shave Columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "996653ec-f5ad-428b-96c9-f93578539051",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_features(data, column_name, exclude_cols, n):\n",
    "\n",
    "    data = data.drop(columns=exclude_cols)\n",
    "\n",
    "    corr_df = data.corr(method='pearson')[[column_name]]\n",
    "    corr_df = corr_df.drop(index=[column_name])\n",
    "    corr_df['Grade_Corr_Abs'] = corr_df[column_name].apply(lambda x: np.abs(x))\n",
    "    corr_df = corr_df.sort_values(by='Grade_Corr_Abs',ascending=False)\n",
    "    corr_df = corr_df[corr_df['Grade_Corr_Abs'] >= 0.01]\n",
    "    top_features = corr_df.head(n).index.tolist()\n",
    "    return top_features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a9940c6-6dc7-4917-be9d-ac08f8c50b4c",
   "metadata": {},
   "source": [
    "# Before Midterm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8148d38e-4f37-4f1e-8028-7ad1e564ae1e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "21baac2feea848e7be4abf3e32e78752",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/57 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e6fb54f7a1764628a82a2be9a9c7e12b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/57 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "da68c2646b2c4455a31c003377daa6a9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/57 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fc21982ab2bb4ddda714ad1b9fc72faf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/57 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "53a217273f294f7fbd689535dee2aea9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/57 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d181f96fa634444c9f073035daa65106",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/57 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "94f0cf0ae9db458cb22244f43381669c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/57 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c545d6ec85fe43d19f39dc27cb457eed",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/57 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d3067e5804cf46e9b799e3da42feee60",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/57 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8c0ce93bccc14336a163e2ba6a41786d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/57 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------Averaged Perceptron (10 perceptrons)------------------------------\n",
      "\n",
      "Averaged weight vector shape: [37.71857245 17.80586082 30.43779938  1.94999998 -8.1822228  -1.6       ]\n",
      "Averaged bias value: -26.2000\n",
      "\n",
      "The number of correct preds was 557 for acc of 61.88888888888889%\n",
      "The number of pos preds was 898 and neg num was 2\n",
      "\n",
      "======================================================================\n",
      "Detailed Evaluation Metrics:\n",
      "======================================================================\n",
      "Accuracy: 61.89%\n",
      "Precision: 0.6180\n",
      "Recall: 1.0000\n",
      "F1-Score: 0.7639\n",
      "\n",
      "Confusion Matrix:\n",
      "                Predicted\n",
      "              Fail    Pass\n",
      "Actual Fail      2    343\n",
      "       Pass      0    555\n",
      "\n",
      "Predictions breakdown:\n",
      "  Predicted Fail (0): 2\n",
      "  Predicted Pass (1): 898\n",
      "  Actual Fail (0): 345\n",
      "  Actual Pass (1): 555\n"
     ]
    }
   ],
   "source": [
    "# Averaged Perceptron: Train 10 perceptrons and average their weights\n",
    "n_perceptrons = 10\n",
    "weight_vecs = []\n",
    "bias_vecs = []\n",
    "features_lst = get_features(education_data, 'Grade', ['Total_Score','Midterm_Score','Final_Score','Projects_Score'], 10)\n",
    "num_feat = len(features_lst)\n",
    "batch_size = 64\n",
    "shuffle = True\n",
    "for i in range(n_perceptrons):\n",
    "    train_ds = MyDataset(train_df, features_lst, 'Grade')\n",
    "    train_dl = DataLoader(train_ds, batch_size=batch_size, shuffle=shuffle)\n",
    "    \n",
    "    w_curr, b_curr, error_curr, weight_hist_curr, tot_train_pos_curr = train_perceptron(train_dl, num_feat, pos_class=1)\n",
    "    \n",
    "    weight_vecs.append(w_curr)\n",
    "    bias_vecs.append(b_curr)\n",
    "\n",
    "# Average the weights and biases\n",
    "w_avg = np.mean(weight_vecs, axis=0)\n",
    "b_avg = np.mean(bias_vecs, axis=0)\n",
    "\n",
    "print(f\"-------------------Averaged Perceptron (10 perceptrons)------------------------------\\n\")\n",
    "print(f\"Averaged weight vector shape: {w_avg}\")\n",
    "print(f\"Averaged bias value: {b_avg:.4f}\\n\")\n",
    "\n",
    "# Test on dev.\n",
    "X_dev_a = dev_df[features_lst].to_numpy()\n",
    "dev_y_true = dev_df['Grade'].to_numpy()\n",
    "dev_y_pred = ((X_dev_a @ w_avg + b_avg) > 0).astype(int)\n",
    "n_correct_dev = (dev_y_true==dev_y_pred).sum(axis=0)\n",
    "\n",
    "print(f\"The number of correct preds was {n_correct_dev} for acc of {(n_correct_dev/dev_y_true.shape[0])*100}%\")\n",
    "print(f\"The number of pos preds was {(dev_y_pred==1).sum(axis=0)} and neg num was {(dev_y_pred==0).sum(axis=0)}\")\n",
    "\n",
    "# Additional detailed metrics\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix\n",
    "\n",
    "accuracy = accuracy_score(dev_y_true, dev_y_pred)\n",
    "precision = precision_score(dev_y_true, dev_y_pred, zero_division=0)\n",
    "recall = recall_score(dev_y_true, dev_y_pred, zero_division=0)\n",
    "f1 = f1_score(dev_y_true, dev_y_pred, zero_division=0)\n",
    "cm = confusion_matrix(dev_y_true, dev_y_pred)\n",
    "\n",
    "print(f\"\\n{'='*70}\")\n",
    "print(\"Detailed Evaluation Metrics:\")\n",
    "print(f\"{'='*70}\")\n",
    "print(f\"Accuracy: {accuracy*100:.2f}%\")\n",
    "print(f\"Precision: {precision:.4f}\")\n",
    "print(f\"Recall: {recall:.4f}\")\n",
    "print(f\"F1-Score: {f1:.4f}\")\n",
    "\n",
    "print(f\"\\nConfusion Matrix:\")\n",
    "print(f\"                Predicted\")\n",
    "print(f\"              Fail    Pass\")\n",
    "print(f\"Actual Fail   {cm[0,0]:4d}   {cm[0,1]:4d}\")\n",
    "print(f\"       Pass   {cm[1,0]:4d}   {cm[1,1]:4d}\")\n",
    "\n",
    "print(f\"\\nPredictions breakdown:\")\n",
    "print(f\"  Predicted Fail (0): {(dev_y_pred==0).sum()}\")\n",
    "print(f\"  Predicted Pass (1): {(dev_y_pred==1).sum()}\")\n",
    "print(f\"  Actual Fail (0): {(dev_y_true==0).sum()}\")\n",
    "print(f\"  Actual Pass (1): {(dev_y_true==1).sum()}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e53ee25d-dc0c-4190-9dcd-2dc9fa9225dc",
   "metadata": {},
   "source": [
    "# After Midterm and before Final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "171a5f7a-2ee5-4a90-9165-0dba15049870",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "02882e612c9445ccac4e8e2bf3c498f0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/57 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "48b67a4028854d2fab96ea74b2113aa5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/57 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "811e8d705e88441d8280eda1ec4b9552",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/57 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "359be7d984df41ab85c68be4d0068e46",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/57 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d7cb4de08d4e4e92997fd9f6aa15ccc1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/57 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "92446baa0717486a91c9f36272a75888",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/57 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "73347eaeeac345c987b3317052ad42f2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/57 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5d3797eee74d4d67b1a815c1803892a2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/57 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6687c7ae4cf2486ea8e1977337ce81be",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/57 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "750e681b173e4c6199726d2972a27241",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/57 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------Averaged Perceptron (10 perceptrons)------------------------------\n",
      "\n",
      "Averaged weight vector shape: [ 32.39464005  38.86777661  15.10251047  27.95419947  -4.61000013\n",
      " -15.63888958  -1.5       ]\n",
      "Averaged bias value: -37.0000\n",
      "\n",
      "The number of correct preds was 564 for acc of 62.66666666666667%\n",
      "The number of pos preds was 885 and neg num was 15\n",
      "\n",
      "======================================================================\n",
      "Detailed Evaluation Metrics:\n",
      "======================================================================\n",
      "Accuracy: 62.67%\n",
      "Precision: 0.6237\n",
      "Recall: 0.9946\n",
      "F1-Score: 0.7667\n",
      "\n",
      "Confusion Matrix:\n",
      "                Predicted\n",
      "              Fail    Pass\n",
      "Actual Fail     12    333\n",
      "       Pass      3    552\n",
      "\n",
      "Predictions breakdown:\n",
      "  Predicted Fail (0): 15\n",
      "  Predicted Pass (1): 885\n",
      "  Actual Fail (0): 345\n",
      "  Actual Pass (1): 555\n"
     ]
    }
   ],
   "source": [
    "# Averaged Perceptron: Train 10 perceptrons and average their weights\n",
    "n_perceptrons = 10\n",
    "weight_vecs = []\n",
    "bias_vecs = []\n",
    "features_lst = features_lst = get_features(education_data, 'Grade', ['Total_Score','Final_Score','Projects_Score'], 10)\n",
    "\n",
    "num_feat = len(features_lst)\n",
    "\n",
    "for i in range(n_perceptrons):\n",
    "    train_ds = MyDataset(train_df, features_lst, 'Grade')\n",
    "    train_dl = DataLoader(train_ds, batch_size=batch_size, shuffle=shuffle)\n",
    "    \n",
    "    w_curr, b_curr, error_curr, weight_hist_curr, tot_train_pos_curr = train_perceptron(train_dl, num_feat, pos_class=1)\n",
    "    \n",
    "    weight_vecs.append(w_curr)\n",
    "    bias_vecs.append(b_curr)\n",
    "\n",
    "# Average the weights and biases\n",
    "w_avg = np.mean(weight_vecs, axis=0)\n",
    "b_avg = np.mean(bias_vecs, axis=0)\n",
    "\n",
    "print(f\"-------------------Averaged Perceptron (10 perceptrons)------------------------------\\n\")\n",
    "print(f\"Averaged weight vector shape: {w_avg}\")\n",
    "print(f\"Averaged bias value: {b_avg:.4f}\\n\")\n",
    "\n",
    "# Test on dev.\n",
    "X_dev_a = dev_df[features_lst].to_numpy()\n",
    "dev_y_true = dev_df['Grade'].to_numpy()\n",
    "dev_y_pred = ((X_dev_a @ w_avg + b_avg) > 0).astype(int)\n",
    "n_correct_dev = (dev_y_true==dev_y_pred).sum(axis=0)\n",
    "\n",
    "print(f\"The number of correct preds was {n_correct_dev} for acc of {(n_correct_dev/dev_y_true.shape[0])*100}%\")\n",
    "print(f\"The number of pos preds was {(dev_y_pred==1).sum(axis=0)} and neg num was {(dev_y_pred==0).sum(axis=0)}\")\n",
    "\n",
    "# Additional detailed metrics\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix\n",
    "\n",
    "accuracy = accuracy_score(dev_y_true, dev_y_pred)\n",
    "precision = precision_score(dev_y_true, dev_y_pred, zero_division=0)\n",
    "recall = recall_score(dev_y_true, dev_y_pred, zero_division=0)\n",
    "f1 = f1_score(dev_y_true, dev_y_pred, zero_division=0)\n",
    "cm = confusion_matrix(dev_y_true, dev_y_pred)\n",
    "\n",
    "print(f\"\\n{'='*70}\")\n",
    "print(\"Detailed Evaluation Metrics:\")\n",
    "print(f\"{'='*70}\")\n",
    "print(f\"Accuracy: {accuracy*100:.2f}%\")\n",
    "print(f\"Precision: {precision:.4f}\")\n",
    "print(f\"Recall: {recall:.4f}\")\n",
    "print(f\"F1-Score: {f1:.4f}\")\n",
    "\n",
    "print(f\"\\nConfusion Matrix:\")\n",
    "print(f\"                Predicted\")\n",
    "print(f\"              Fail    Pass\")\n",
    "print(f\"Actual Fail   {cm[0,0]:4d}   {cm[0,1]:4d}\")\n",
    "print(f\"       Pass   {cm[1,0]:4d}   {cm[1,1]:4d}\")\n",
    "\n",
    "print(f\"\\nPredictions breakdown:\")\n",
    "print(f\"  Predicted Fail (0): {(dev_y_pred==0).sum()}\")\n",
    "print(f\"  Predicted Pass (1): {(dev_y_pred==1).sum()}\")\n",
    "print(f\"  Actual Fail (0): {(dev_y_true==0).sum()}\")\n",
    "print(f\"  Actual Pass (1): {(dev_y_true==1).sum()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80d8a928-6a3c-4c0c-bc9a-523a88141e52",
   "metadata": {},
   "source": [
    "# After Final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "12eafc0b-00f4-422e-9f14-1a60c78849d6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6368342e90084c879289f4a0cefe1641",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/57 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "64232511f4eb4e78b277e9c75063b6a1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/57 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "06214242a6d14cac8ef996beced9b7e7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/57 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0ce7e923a63445aaa2831a15caba022c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/57 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4610636cc9c34fb7a408aeb7f821bea9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/57 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e847e65803d04206b0a8b3ba6003bbb3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/57 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3dfc99dac25340df8d5c5d6bdbf3a785",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/57 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f339f160ec444a00be347e2863a3bc4d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/57 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5f671f6f5f77472b8e3a226c86324cb5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/57 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f0885ead9c544f57bd0207b9486fc8e5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/57 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------Averaged Perceptron (10 perceptrons)------------------------------\n",
      "\n",
      "Averaged weight vector shape: [ 85.82600546  63.3842903   12.35861642  25.11083091  -7.74887449\n",
      "  26.11179943 -13.55000019 -35.11333377  -5.1       ]\n",
      "Averaged bias value: -66.9000\n",
      "\n",
      "The number of correct preds was 576 for acc of 64.0%\n",
      "The number of pos preds was 879 and neg num was 21\n",
      "\n",
      "======================================================================\n",
      "Detailed Evaluation Metrics:\n",
      "======================================================================\n",
      "Accuracy: 64.00%\n",
      "Precision: 0.6314\n",
      "Recall: 1.0000\n",
      "F1-Score: 0.7741\n",
      "\n",
      "Confusion Matrix:\n",
      "                Predicted\n",
      "              Fail    Pass\n",
      "Actual Fail     21    324\n",
      "       Pass      0    555\n",
      "\n",
      "Predictions breakdown:\n",
      "  Predicted Fail (0): 21\n",
      "  Predicted Pass (1): 879\n",
      "  Actual Fail (0): 345\n",
      "  Actual Pass (1): 555\n"
     ]
    }
   ],
   "source": [
    "# Averaged Perceptron: Train 10 perceptrons and average their weights\n",
    "n_perceptrons = 10\n",
    "weight_vecs = []\n",
    "bias_vecs = []\n",
    "features_lst = features_lst = get_features(education_data, 'Grade', ['Total_Score'], 10)\n",
    "\n",
    "num_feat = len(features_lst)\n",
    "\n",
    "for i in range(n_perceptrons):\n",
    "    train_ds = MyDataset(train_df, features_lst, 'Grade')\n",
    "    train_dl = DataLoader(train_ds, batch_size=batch_size, shuffle=shuffle)\n",
    "    \n",
    "    w_curr, b_curr, error_curr, weight_hist_curr, tot_train_pos_curr = train_perceptron(train_dl, num_feat, pos_class=1)\n",
    "    \n",
    "    weight_vecs.append(w_curr)\n",
    "    bias_vecs.append(b_curr)\n",
    "\n",
    "# Average the weights and biases\n",
    "w_avg = np.mean(weight_vecs, axis=0)\n",
    "b_avg = np.mean(bias_vecs, axis=0)\n",
    "\n",
    "print(f\"-------------------Averaged Perceptron (10 perceptrons)------------------------------\\n\")\n",
    "print(f\"Averaged weight vector shape: {w_avg}\")\n",
    "print(f\"Averaged bias value: {b_avg:.4f}\\n\")\n",
    "\n",
    "# Test on dev.\n",
    "X_dev_a = dev_df[features_lst].to_numpy()\n",
    "dev_y_true = dev_df['Grade'].to_numpy()\n",
    "dev_y_pred = ((X_dev_a @ w_avg + b_avg) > 0).astype(int)\n",
    "n_correct_dev = (dev_y_true==dev_y_pred).sum(axis=0)\n",
    "\n",
    "print(f\"The number of correct preds was {n_correct_dev} for acc of {(n_correct_dev/dev_y_true.shape[0])*100}%\")\n",
    "print(f\"The number of pos preds was {(dev_y_pred==1).sum(axis=0)} and neg num was {(dev_y_pred==0).sum(axis=0)}\")\n",
    "\n",
    "# Additional detailed metrics\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix\n",
    "\n",
    "accuracy = accuracy_score(dev_y_true, dev_y_pred)\n",
    "precision = precision_score(dev_y_true, dev_y_pred, zero_division=0)\n",
    "recall = recall_score(dev_y_true, dev_y_pred, zero_division=0)\n",
    "f1 = f1_score(dev_y_true, dev_y_pred, zero_division=0)\n",
    "cm = confusion_matrix(dev_y_true, dev_y_pred)\n",
    "\n",
    "print(f\"\\n{'='*70}\")\n",
    "print(\"Detailed Evaluation Metrics:\")\n",
    "print(f\"{'='*70}\")\n",
    "print(f\"Accuracy: {accuracy*100:.2f}%\")\n",
    "print(f\"Precision: {precision:.4f}\")\n",
    "print(f\"Recall: {recall:.4f}\")\n",
    "print(f\"F1-Score: {f1:.4f}\")\n",
    "\n",
    "print(f\"\\nConfusion Matrix:\")\n",
    "print(f\"                Predicted\")\n",
    "print(f\"              Fail    Pass\")\n",
    "print(f\"Actual Fail   {cm[0,0]:4d}   {cm[0,1]:4d}\")\n",
    "print(f\"       Pass   {cm[1,0]:4d}   {cm[1,1]:4d}\")\n",
    "\n",
    "print(f\"\\nPredictions breakdown:\")\n",
    "print(f\"  Predicted Fail (0): {(dev_y_pred==0).sum()}\")\n",
    "print(f\"  Predicted Pass (1): {(dev_y_pred==1).sum()}\")\n",
    "print(f\"  Actual Fail (0): {(dev_y_true==0).sum()}\")\n",
    "print(f\"  Actual Pass (1): {(dev_y_true==1).sum()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "71f40813-920e-4707-bfed-f2398d86c486",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15 Examples of False Positives (Predicted Pass, Actual Fail):\n",
      "    Attendance (%)  Extracurricular_Activities  Midterm_Score  Final_Score  \\\n",
      "1           0.9268                         1.0       0.603360     0.710042   \n",
      "8           0.7032                         1.0       0.411441     0.836767   \n",
      "13          0.7736                         0.0       0.979498     0.413983   \n",
      "16          0.6804                         1.0       0.574957     0.423885   \n",
      "19          0.5296                         0.0       0.783878     0.552310   \n",
      "20          0.6814                         1.0       0.958296     0.563913   \n",
      "22          0.7290                         1.0       0.971997     0.464093   \n",
      "23          0.8730                         0.0       0.754075     0.493599   \n",
      "27          0.9662                         0.0       0.799680     0.506701   \n",
      "31          0.6687                         0.0       0.722572     0.886677   \n",
      "32          0.6847                         1.0       0.570757     0.606521   \n",
      "36          0.5746                         0.0       0.472847     0.515303   \n",
      "37          0.6560                         0.0       0.765777     0.755651   \n",
      "40          0.5627                         1.0       0.680768     0.426285   \n",
      "41          0.9388                         1.0       0.784678     0.502801   \n",
      "\n",
      "    Assignments_Avg  Quizzes_Avg  Participation_Score  Projects_Score  \\\n",
      "1          0.856786     0.554655                0.057          0.7640   \n",
      "8          0.667667     0.614661                0.682          0.6264   \n",
      "13         0.956896     0.949595                0.237          0.6073   \n",
      "16         0.777378     0.817282                0.556          0.6932   \n",
      "19         0.602160     0.769877                0.822          0.6937   \n",
      "20         0.691169     0.744874                0.640          0.5680   \n",
      "22         0.646365     0.846885                0.045          0.5990   \n",
      "23         0.914591     0.706071                0.505          0.5287   \n",
      "27         0.774977     0.543554                0.364          0.7142   \n",
      "31         0.549455     0.778678                0.133          0.6685   \n",
      "32         0.536654     0.853085                0.265          0.7431   \n",
      "36         0.570657     0.884488                0.723          0.5113   \n",
      "37         0.549955     0.542654                0.213          0.5373   \n",
      "40         0.671267     0.611061                0.867          0.6250   \n",
      "41         0.628963     0.622562                0.748          0.5317   \n",
      "\n",
      "    Stress_Level (1-10)  Sleep_Hours_per_Night  Grade  \n",
      "1                   0.3               0.911111    0.0  \n",
      "8                   0.8               0.488889    0.0  \n",
      "13                  0.1               0.844444    0.0  \n",
      "16                  0.4               0.811111    0.0  \n",
      "19                  0.1               0.888889    0.0  \n",
      "20                  0.7               0.766667    0.0  \n",
      "22                  0.3               0.788889    0.0  \n",
      "23                  1.0               0.533333    0.0  \n",
      "27                  0.5               0.922222    0.0  \n",
      "31                  0.6               0.688889    0.0  \n",
      "32                  1.0               0.966667    0.0  \n",
      "36                  0.1               0.711111    0.0  \n",
      "37                  0.8               0.811111    0.0  \n",
      "40                  0.4               0.833333    0.0  \n",
      "41                  0.1               0.477778    0.0  \n",
      "\n",
      "10 Examples of False Negatives (Predicted Fail, Actual Pass):\n",
      "Empty DataFrame\n",
      "Columns: [Attendance (%), Extracurricular_Activities, Midterm_Score, Final_Score, Assignments_Avg, Quizzes_Avg, Participation_Score, Projects_Score, Stress_Level (1-10), Sleep_Hours_per_Night, Grade]\n",
      "Index: []\n"
     ]
    }
   ],
   "source": [
    "# Find False Positives (FP): Predicted Pass (1) but actual Fail (0)\n",
    "false_pos_indices = np.where((dev_y_pred == 1) & (dev_y_true == 0))[0]\n",
    "false_pos_examples = dev_df.iloc[false_pos_indices]\n",
    "\n",
    "# Find False Negatives (FN): Predicted Fail (0) but actual Pass (1)\n",
    "false_neg_indices = np.where((dev_y_pred == 0) & (dev_y_true == 1))[0]\n",
    "false_neg_examples = dev_df.iloc[false_neg_indices]\n",
    "\n",
    "# Get top 15 false positives and top 10 false negatives\n",
    "false_pos_examples_top_15 = false_pos_examples.head(15)\n",
    "false_neg_examples_top_10 = false_neg_examples.head(10)\n",
    "\n",
    "# Print out the examples\n",
    "print(\"15 Examples of False Positives (Predicted Pass, Actual Fail):\")\n",
    "print(false_pos_examples_top_15[['Attendance (%)', 'Extracurricular_Activities', 'Midterm_Score', 'Final_Score', \n",
    "                                  'Assignments_Avg', 'Quizzes_Avg', 'Participation_Score', 'Projects_Score', \n",
    "                                  'Stress_Level (1-10)', 'Sleep_Hours_per_Night', 'Grade']])\n",
    "\n",
    "print(\"\\n10 Examples of False Negatives (Predicted Fail, Actual Pass):\")\n",
    "print(false_neg_examples_top_10[['Attendance (%)', 'Extracurricular_Activities', 'Midterm_Score', 'Final_Score', \n",
    "                                  'Assignments_Avg', 'Quizzes_Avg', 'Participation_Score', 'Projects_Score', \n",
    "                                  'Stress_Level (1-10)', 'Sleep_Hours_per_Night', 'Grade']])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b3d9e2fb-ac0b-46aa-bda3-7f322dca0d6e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of correct preds was 314 for acc of 62.8%\n",
      "The number of pos preds was 487 and neg num was 13\n",
      "\n",
      "======================================================================\n",
      "Detailed Evaluation Metrics:\n",
      "======================================================================\n",
      "Accuracy: 62.80%\n",
      "Precision: 0.6181\n",
      "Recall: 1.0000\n",
      "F1-Score: 0.7640\n",
      "\n",
      "Confusion Matrix:\n",
      "                Predicted\n",
      "              Fail    Pass\n",
      "Actual Fail     13    186\n",
      "       Pass      0    301\n",
      "\n",
      "Predictions breakdown:\n",
      "  Predicted Fail (0): 13\n",
      "  Predicted Pass (1): 487\n",
      "  Actual Fail (0): 199\n",
      "  Actual Pass (1): 301\n"
     ]
    }
   ],
   "source": [
    "# Test on Test.\n",
    "X_test_a = test_df[features_lst].to_numpy()\n",
    "test_y_true = test_df['Grade'].to_numpy()\n",
    "test_y_pred = ((X_test_a @ w_avg + b_avg) > 0).astype(int)\n",
    "n_correct_test = (test_y_true==test_y_pred).sum(axis=0)\n",
    "\n",
    "print(f\"The number of correct preds was {n_correct_test} for acc of {(n_correct_test/test_y_true.shape[0])*100}%\")\n",
    "print(f\"The number of pos preds was {(test_y_pred==1).sum(axis=0)} and neg num was {(test_y_pred==0).sum(axis=0)}\")\n",
    "\n",
    "# Additional detailed metrics\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix\n",
    "\n",
    "accuracy = accuracy_score(test_y_true, test_y_pred)\n",
    "precision = precision_score(test_y_true, test_y_pred, zero_division=0)\n",
    "recall = recall_score(test_y_true, test_y_pred, zero_division=0)\n",
    "f1 = f1_score(test_y_true, test_y_pred, zero_division=0)\n",
    "cm = confusion_matrix(test_y_true, test_y_pred)\n",
    "\n",
    "print(f\"\\n{'='*70}\")\n",
    "print(\"Detailed Evaluation Metrics:\")\n",
    "print(f\"{'='*70}\")\n",
    "print(f\"Accuracy: {accuracy*100:.2f}%\")\n",
    "print(f\"Precision: {precision:.4f}\")\n",
    "print(f\"Recall: {recall:.4f}\")\n",
    "print(f\"F1-Score: {f1:.4f}\")\n",
    "\n",
    "print(f\"\\nConfusion Matrix:\")\n",
    "print(f\"                Predicted\")\n",
    "print(f\"              Fail    Pass\")\n",
    "print(f\"Actual Fail   {cm[0,0]:4d}   {cm[0,1]:4d}\")\n",
    "print(f\"       Pass   {cm[1,0]:4d}   {cm[1,1]:4d}\")\n",
    "\n",
    "print(f\"\\nPredictions breakdown:\")\n",
    "print(f\"  Predicted Fail (0): {(test_y_pred==0).sum()}\")\n",
    "print(f\"  Predicted Pass (1): {(test_y_pred==1).sum()}\")\n",
    "print(f\"  Actual Fail (0): {(test_y_true==0).sum()}\")\n",
    "print(f\"  Actual Pass (1): {(test_y_true==1).sum()}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
